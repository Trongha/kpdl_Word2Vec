Sequence Modeling: Recurrent and Recursive Nets
(Mô hình tuần tự: mạng hồi quy và mạng đệ quy)
Recurrent neural networks (Mạng nơron hồi quy) - RNN (Rumelhart và cộng sự, 1986a) là một mạng lưới nơron để xử lý dữ liệu tuần tự. Mặc dù mạng lưới liên kết là mạng nơron chuyên xử lý một tập các giá trị X chẳng hạn như hình ảnh thì RNN là mạng nơron chuyên biệt cho xử lý một chuỗi các giá trị x(1), …, x(τ). Cũng giống như các convolutional networks, nó có thể dễ dàng co dãn tỷ lệ hình ảnh có chiều rộng và chiều cao lớn, và một số convolutional networks có thể xử lý hình ảnh có kích thước thay đổi, Recursive Networks có thể mở rộng đến nhiều chuỗi dài hơn thực tế đối với các mạng lưới không có chuỗi dựa trên trình tự chuyên môn hóa. Hầu hết các Recursive Nets cũng có thể xử lý các chuỗi có chiều dài thay đổi.

Để chuyển từ mạng đa chiều sang Recursive Networks, chúng ta cần tận dụng một trong những ý tưởng ban đầu được tìm thấy trong các mô hình học máy và thống kê những năm 1980: chia sẻ các thông số trên các phần khác nhau của một mô hình. Việc chia sẻ thông số giúp cho nó có thể mở rộng và ứng dụng mô hình cho các ví dụ theo các hình thức khác nhau (ở đây là độ dài khác nhau) và tổng quát lên chúng. Nếu ta có thông số riêng đối với mỗi giá trị của từng thời điểm, chúng ta không thể khái quát hóa độ dài một chuỗi mà ta không thấy trong quá trình training, cũng như không thể chia sẻ sức mạnh thống kê qua các độ dài chuỗi khác nhau và qua các vị trí khác nhau trong cùng thời điểm, chia sẻ như vậy đặc biệt quan trọng khi một thông tin cụ thể có thể xảy ra tại nhiều vị trí trong chuỗi. Ví dụ, hãy xem xét hai câu “I went to Nepal in 2009” và “In 2009, I went to Nepal.” Nếu chúng ta yêu cầu một mô hình học máy để đọc từng câu và trích xuất năm mà người kể chuyện đến Nepal, chúng ta muốn nó nhận ra rằng là năm 2009 là phần thông tin có liên quan, cho dù nó xuất hiện trong ở vị trí nào trong câu đi chăng nữa. Giả sử rằng chúng ta đã đào tạo một feedforward network xử lý các câu có độ dài cố định. Một kết nối truyền thống được kết nối hoàn toàn đến mạng feedforward sẽ có các tham số riêng biệt cho mỗi tính năng đầu vào, vì vậy nó sẽ cần phải tìm hiểu tất cả các quy tắc về mặt ngôn ngữ một cách riêng biệt tại mỗi vị trí trong câu. Bằng cách so sánh, một RNN sẽ chia sẻ dữ liệu dự trên điều kiện cùng trọng số qua một vài bước.

Một ý tưởng liên quan là sử dụng việc chuyển đổi qua một không gian 1 chiều. đây cách tiếp cận chập chững nhưng là nền tảng cho các mạng nơron thời gian trễ (Lang và Hinton, 1988; Waibel và cộng sự, 1989; Lang và cộng sự, 1990). Các phép tích chập cho phép 1 mạng chia sẻ các thông số theo từng thời điểm, nhưng là nông cạn. Đầu ra của việc chuyển đổi là một chuỗi trong đó mỗi phần tử của output là một hàm của một số lượng nhỏ các thành viên lân cận của input. Ý tưởng chia sẻ tham số trong ứng dụng của tích chập tương tự ở mỗi bước thời gian. Các Recurrent networks chia sẻ các thông số theo một cách khác, mỗi phần tử của đầu ra là một hàm của phần tử trước đó. Mỗi thành viên của Output được tạo ra bằng cách sử dụng cùng một quy tắc cập nhật được áp dụng cho các kết quả đầu ra trước đó. Công thức lặp lại này khiến việc chia sẻ các thông số thông qua một đồ thị tính toán sâu.

Để đơn giản, chúng ta đề cập đến RNNs hoạt động trên một chuỗi có chứa vectơ x(t) với chỉ số thời gian t từ 1 đến τ. Trong thực tế, các mạng thường xuyên hoạt động trên các minibatch (khối con) của các chuỗi như vậy, với độ dài chuỗi khác nhau τ cho mỗi thành viên của minibatch. Chúng ta có bỏ qua các chỉ số minibatch để đơn giản hóa ký hiệu. Hơn nữa, chỉ số thời gian không cần phải theo nghĩa đen ám chỉ thời gian trôi qua trong thế giới thực. Đôi khi nó đề cập đến chỉ đến vị trí trong chuỗi (index). RNN cũng có thể được áp dụng trong hai chiều trên dữ liệu không gian như hình ảnh và thậm chí khi được áp dụng cho dữ liệu liên quan đến thời gian, có thể có các kết nối quay ngược thời gian, với điều kiện toàn bộ chuỗi được quan sát trước khi nó được cung cấp cho RNN.
Để biết thêm thông tin về RNN, chúng tôi giới thiệu người đọc đến sách giáo khoa của Graves (2012).

10.1. Unfolding Computational Graphs (Đồ thị tính toán mở rộng)
Đồ thị tính toán là một cách để hợp thức hóa cấu trúc của một tập các phép tính, chẳng hạn như những người tham gia vào việc lập bản đồ đầu vào, tham số cho đầu ra và mất mát. Bạn hãy xem mục 6.5.1 để có phần giới thiệu chung. Trong phần này chúng tôi giải thích ý tưởng unfolding một tính toán đệ quy hoặc tái diễn vào một tính toán biểu đồ có cấu trúc lặp lại, thường tương ứng với chuỗi sự kiện. Việc mở rộng biểu đồ này sẽ dẫn đến việc chia sẻ thông số trên một mạng sâu kết cấu.
Ví dụ, hãy xem xét dạng cổ điển của một hệ thống:
s(t) = f(s(t-1); θ),							 (10.1)
trong đó s(t) được gọi là trạng thái của hệ thống.
Phương trình 10.1 có sự hồi quy bởi vì định nghĩa của s tại thời điểm t đề cập đến thời điểm t - 1. Đối với số time step hữu hạn τ, biểu đồ có thể được mở ra bằng cách áp dụng định nghĩa τ - 1 lần. Ví dụ, nếu chúng ta mở rộng phương trình 10.1 cho τ = 3, chúng tôi có được
s(3) = f(s(2); θ),							 (10.2)
 = f(f(s(1); θ) ; θ),							 (10.3)
Mở rộng phương trình bằng cách lặp lại việc áp dụng định nghĩa, cách này mang lại một biểu thức không liên quan đến sự hồi quy, bây giờ nó được biểu diễn bằng đồ thị tính toán theo chu kỳ truyền thống. Các Unfolding Computational Graphs của phương trình 10.1 và phương trình 10.3 được minh họa trong hình 10.1.
 (10.1)
Hình 10.1: Hệ thống động học cổ điển được mô tả theo phương trình 10.1, được coi như một Unfolding Computational Graphs. Mỗi nút thể hiện trạng thái tại một số thời điểm và hàm f ánh xạ trạng thái tại t tới trạng thái tại t + 1. Các tham số giống nhau (cùng một giá trị θ với vai trò là tham số) được sử dụng cho tất cả các bước thời gian. Một ví dụ khác, chúng ta hãy xem xét một hệ thống lực thúc đẩy bởi một bên ngoài tín hiệu x(t)
s(t) = f(s(t-1), x(t) ; θ),							 (10.4)
chúng ta thấy rằng trạng thái hiện tại chứa thông tin về toàn bộ chuỗi quá khứ.
RNN có thể được xây dựng theo nhiều cách khác nhau. Hầu như chức năng nào cũng có thể được coi là mạng thần kinh feedforward, về bản chất bất kỳ chức năng liên quan đến hồi quy có thể được coi là một RNN. 
Nhiều RNN sử dụng phương trình 10.5 hoặc một phương trình tương tự để xác định giá trị của các đơn vị ẩn. Để chỉ ra rằng trạng thái là đơn vị ẩn, bây giờ chúng ta viết lại phương trình 10.4 bằng lấy h để đại diện:
h(t) = f(s(t-1), x(t) ; θ),						 (10.5)
minh họa trong hình 10.2, RNNs điển hình sẽ thêm các tính năng kiến trúc bổ sung, như vậy là các lớp đầu ra đọc thông tin output từ trạng thái h để đưa ra các dự đoán.
Khi Recurrent network được huấn luyện để thực hiện một nhiệm vụ đòi hỏi phải dự đoán tương lai từ quá khứ, mạng thường học cách sử dụng h(t) như một hàm mất mát tóm tắt các khía cạnh liên quan đến nhiệm vụ của chuỗi các đầu vào trong quá khứ ảnh hưởng tới t. Điều này nói chung là mất mát, vì nó ánh xạ một chuỗi chiều dài tùy ý (x (t), x (t − 1), x (t − 2),.,., x (2), x(1)) đến một vectơ chiều dài cố định h (t). Tùy thuộc vào tiêu chí. Bản tóm tắt này có thể chọn lọc giữ một số khía cạnh với độ chính xác cao hơn các khía cạnh khác. Ví dụ, nếu RNN được sử dụng trong mô hình ngôn ngữ thống kê, thường để dự đoán từ tiếp theo dựa vào các từ trước đó, có thể việc lưu trữ tất cả thông tin về input cho đến thời điểm t là không cần thiết, nhưng vẫn đủ thông tin để dự đoán phần còn lại của câu. Tình huống khắt khe nhất là khi chúng ta yêu cầu h(t) đủ “giàu” để cho phép một khoảng khôi phục chuỗi đầu vào, như trong cơ cấu tự động hóa (chương 14).
 (10.2)
Hình 10.2: Recurrent network không có đầu ra. Recurrent network này chỉ là các quá trình đưa input x vào trạng thái h được chuyển tiếp qua thời gian bằng cách kết hợp nào đó (bên trái). Hình vuông màu đen biểu thị sự chậm trễ của một bước. Bên phải, một mạng lưới tương tự được thấy dưới dạng Unfolding Computational Graphs, trong đó mỗi nút đang được kết hợp với một cá thể thời gian cụ thể.
Phương trình 10.5 có thể được vẽ theo hai cách khác nhau. Một cách để vẽ RNN : một sơ đồ chứa một nút cho mỗi thành phần có thể tồn tại trong một bước thục nghiệm vật lý, chẳng hạn như mạng nơron sinh học. Nhìn chung, mạng lưới xác định một mạch hoạt động trong thời gian thực, với các thành phần vật lý ở trạng thái hiện tại có thể ảnh hưởng đến trạng thái tương lai của chúng, bên trái của hình 10.2. Trong suốt chương này, chúng ta sử dụng một hình vuông màu đen trong sơ đồ mạch để biểu thị rằng một tương tác diễn ra với sự chậm trễ của một bước thời gian, từ trạng thái tại thời điểm t đến trạng thái tại thời điểm t + 1. Cách khác để vẽ RNN là vẽ Unfolding Computational Graphs, trong đó mỗi thành phần được biểu diễn bởi nhiều các biến khác nhau, với một biến cho mỗi một time step, đại diện cho trạng thái tại thời điểm đó. Mỗi biến cho mỗi time step được vẽ như một nút riêng biệt của biểu đồ tính toán, bên phải của hình 10.2. Những gì chúng tôi gọi unfolding (bày ra) chính là hoạt động ánh xạ một mạch phía bên trái của hình vào một computational graph với các phần lặp lại ở phía bên phải. Mở ra biểu đồ có kích thước phụ thuộc vào độ dài chuỗi.

Chúng ta có thể biểu diễn sự hồi quy mở rộng sau vài bước t với hàm g(t):
h(t) = g(t) (x(t)	,x(t-1), x(t-2),…,x(2), x(1)) 			(10.6
 	 = f (h(t-1), x(t) ; θ)					 (10.7)
Hàm g (t) lấy toàn bộ chuỗi quá khứ (x (t), x (t − 1), x (t − 2),.., x (2), x(1)) làm đầu vào và tạo ra trạng thái hiện tại, nhưng cấu trúc hồi quy mở rộng cho phép chúng ta đưa g(t) vào ứng dụng lặp lại của hàm f. Việc này có 2 ưu điểm chính:
1. Bất kể độ dài chuỗi, mô hình học được luôn có cùng kích thước đầu vào, bởi vì nó được xác định trong điều kiện chuyển đổi từ một trạng thái sang một trạng thái khác, thay vì được xác định theo tiêu chí thay đổi độ dài của ca làm việc.
2. Có thể sử dụng cùng hàm chuyển tiếp f với cùng các tham số ở mọi time step.
Hai yếu tố này làm cho nó có thể học một mô hình hoạt động trên tất cả các time step và tất cả các độ dài chuỗi, thay vì cần phải tìm hiểu riêng biệt mô hình g(t) tại tất cả thời điểm có thể. Học một mô hình chia sẻ cho phép tổng quát về độ dài chuỗi mà chưa xuất hiện trong tập training và cho phép mô hình ước tính được các ví dụ đào tạo ít hơn rất nhiều so với cần thiết mà không cần chia sẻ thông số.
Cả recurrent graph và unrolled graph đều có công dụng của chúng. Các cách lặp lại biểu đồ ngắn gọn. Biểu đồ bày ra một mô tả rõ ràng về tính toán. Unfolded graph - Biểu đồ mở rộng cũng giúp minh họa ý tưởng luồng thông tin chuyển tiếp theo thời gian (đầu ra tính toán và sự thất thoát) và ngược trong thời gian (gradient máy tính) bằng cách hiển thị rõ ràng đường dẫn kèm theo với luồng thông tin.
10.2. Recurrent Neural Networks
Với các ý tưởng phân tích đồ thị và tham số của phần 10.1, chúng ta có thể thiết kế một loạt các Recurrent Neural Networks. Một số ví dụ về các mẫu thiết kế quan trọng cho các Recurrent Neural Networks như sau:
• Các Recurrent Networks tạo ra một output ở mỗi bước và có kết nối hồi quy giữa các đơn vị ẩn, được minh họa trong hình 10.3.
• Các Recurrent Networks tạo ra một output ở mỗi bước và chỉ có kết nối hồi quy từ đầu ra tới đơn vị ẩn ở bước tiếp theo, được minh họa trong hình 10.4.
• Các Recurrent Networks với các kết nối ngược lại giữa các đơn vị ẩn, toàn bộ chuỗi cho một đầu ra duy nhất, được minh họa trong hình 10.5.
  Hình 10.3: Đồ thị tính toán để tính độ sai số trong quá trình huấn luyện của Recurrent Network ánh xạ mỗi chuỗi đầu vào của các giá trị x tới một chuỗi giá trị đầu ra o tương ứng. (bên Trái) RNN và sự mất mát của nó được vẽ với các kết nối ngược lại. (bên Phải) Khai triển theo thời gian, mỗi nút ứng với một thời điểm xác định. 
Giá trị mất mát L là độ lệch của dự đoán o với kết quả chính xác tương ứng y (training target). Khi sử dụng các softmax outputs, chúng ta giả định o là các xác suất log phi chuẩn (unnormalized log probabilities). Hàm loss L là biểu thức ŷ = softmax(o) so sánh nó với mục tiêu y. RNN có đầu vào cho các kết nối ẩn được tham số hóa bởi một ma trận trọng số U, các kết nối hồi quy ẩn được tham số hóa bởi một ma trận trọng số W và các kết nối ẩn đến đầu ra được tham số hóa bởi một ma trận trọng số V. Phương trình 10.8 định nghĩa sự lan truyền xuôi trong mô hình này. 
Hình 10.3 là một ví dụ điển hình hợp lý mà chúng ta sẽ quay lại trong suốt chương. Recurrent Neural Network của hình 10.3 và phương trình 10.8 cho thấy rằng bất kỳ chức năng nào được tính toán bởi một máy Turing có thể được tính toán bởi một Recurrent Network có kích thước hữu hạn. Đầu ra có thể được đọc từ RNN sau một số bước có tính tiệm cận tuyến tính trong số bước được sử dụng bởi máy Turing và tuyến tính tiệm cận theo chiều dài của đầu vào (Siegelmann and Sontag, 1991; Siegelmann, 1995; Siegelmann and Sontag, 1995; Hyotyniemi, 1996). Các hàm được tính toán bởi một máy Turing là rời rạc, vì vậy các kết quả này xem xét việc thực hiện chính xác hàm, chứ không phải xấp xỉ. RNN, khi được sử dụng như một máy Turing, lấy một chuỗi nhị phân làm đầu vào và đầu ra của nó phải được phân loại để cung cấp đầu ra nhị phân. Có thể tính toán tất cả các chức năng trong thiết lập này bằng cách sử dụng một RNN cụ thể có kích thước hữu hạn (Siegelmann and Sontag (1995) sử dụng 886 đơn vị). “Đầu vào” của máy Turing là một đặc điểm kỹ thuật của hàm cần được tính toán, vì vậy cùng một mạng mô phỏng máy Turing này là đủ cho mọi vấn đề. Lý thuyết RNN được sử dụng cho các bằng chứng có thể mô phỏng một ngăn xếp không bị chặn bằng cách đại diện cho các hàm kích hoạt (activacations) và các vecto trọng số (weights) của nó với số lượng hợp lý của độ chính xác không bị ràng buộc.
Chúng tôi đang phát triển các phương trình forward propagation (lan truyền thẳng) cho RNN được mô tả trong hình 10.3. Hình này không chỉ rõ lựa chọn hàm kích hoạt cho các đơn vị ẩn. Ở đây chúng tôi giả sử hàm kích hoạt tiếp tuyến hyperbol. Hình này cũng không xác định chính xác hình thức của hàm đầu ra và hàm mất mát. Ở đây chúng tôi giả định rằng đầu ra là rời rạc, như thể RNN được sử dụng để dự đoán từ hoặc ký tự. Một cách tự nhiên để biểu diễn các biến rời rạc là coi đầu ra o là cho các xác suất log không chuẩn hóa của mỗi giá trị có thể có của biến rời rạc. Sau đó chúng ta có thể áp dụng hàm softmax như một bước hậu xử lý để thu được một vectơ ŷ là xác suất chuẩn hóa trên đầu ra (normalized probabilities over the output). Sự làn truyền của mô hình (Forward Propagation) bắt đầu với một đặc tả của trạng thái ban đầu h(0). Sau đó, đối với mỗi bước từ t = 1 đến t = τ, chúng ta áp dụng các phương trình cập nhật sau:
 
Trong đó các tham số là các vectơ bias b và c cùng với các ma trận trọng số U, V và W, tương ứng cho các kết nối đầu vào đến đơn vị ẩn (input-to-hidden), đơn vị ẩn đến đầu ra (hidden-to-output) và các đơn vị ẩn với nhau (hidden-to-hidden). Đây là một ví dụ về một Recurrent Network ánh xạ một chuỗi đầu vào đến một chuỗi đầu ra có cùng độ dài. Tổng mất mát (total loss) cho một chuỗi giá trị x được ghép nối với một chuỗi các giá trị y là tổng số lỗi trên tất cả các bước. Ví dụ, nếu L(t) là hàm âm log-likelihood của y(t) cho x(1),..., x(t) thì:	
 
trong đó pmodel(y(t) | {x(1),..., x(t)}) được cho bằng cách for y(t) in model’s output vector ŷ(t). Tính toán gradient của hàm mất này đối với các tham số là khá khó khăn. Để tính Gradient thì trước tiên là phải tính từ trái sang phải qua hình minh họa 10.3, tiếp theo là một đường lan truyền từ phải sang trái trong mạch. Thời gian chạy là O(τ) và không thể giảm bằng cách chạy song song các bước vì mạch Forward propagation vốn có tuần tự; mỗi bước cần có sử dụng kết quả trong đơn vị ẩn của bước trước để tính nên chỉ có thể được tính sau bước trước đó. Các trạng thái tính trong thể chuyển tiếp phải được lưu trữ cho đến khi chúng được tái sử dụng trong quá trình truyền ngược, do đó chi phí bộ nhớ cũng là O(τ). Thuật toán back-propagation được áp dụng cho mạch chưa được kiểm tra với chi phí O(τ) được gọi là truyền ngược liên hồi (back-propagation through time) hoặc BPTT và được thảo luận thêm trong phần 10.2.2. Mạng nơron với liên kết hồi quy giữa các đơn vị ẩn là rất mạnh mẽ nhưng huấn luyện cũng rất tốn kém về thời gian và bộ nhớ. Vậy có cách nào khác không?
 
Hình 10.4: Một RNN chỉ có sự hồi quy là kết nối phản hồi (feedback connection) từ đầu ra đến lớp ẩn. Tại mỗi bước t, đầu vào x¬¬t, hàm hoạt động của lớp ẩn (hidden layer activations) là h(t), đầu ra là o(t), các mục tiêu là y(t) và mất mát là L(t). (bên Trái) mạch vòng tổng quát. (bên Phải) Khai triển mạch.
Một RNN như hình 10.4 ít mạnh hơn (có thể biểu hiện một tập hợp các hàm nhỏ hơn) so với các hàm biểu diễn trong hình 10.3. RNN trong hình 10.3 có thể chọn bất kỳ thông tin nào nó muốn ở quá khứ bằng cách đặt vào ẩn h của và truyền h tới tương lai. RNN trong hình này được huấn luyện để đặt một giá trị cụ thể vào o, và o là thông tin duy nhất được phép truyền lại sau này. Không có kết nối trực tiếp từ h về sau. Trước đó h được kết nối với hiện tại chỉ là gián tiếp, thông qua các dự đoán o. Trừ khi o là rất nhiều chiều (high-dimensional) và nhiều dữ liệu(rich), nó thường sẽ thiếu thông tin quan trọng từ quá khứ. Điều này làm cho RNN trong hình này kém mạnh hơn, nhưng có thể dễ huấn luyện hơn vì mỗi bước có thể được huấn luyện độc lập với nhau, cho phép sự song song lớn hơn trong quá trình training, Chúng ta sẽ nói thêm về mô hình này trong phần tiếp theo.
10.2.1. Teacher Forcing and Network with Output Recurrent 
(Giáo viên bắt buộc và mạng có tái xuất đầu ra)
Recurrent Network chỉ có các kết nối từ đầu ra tại một bước tới các đơn vị ẩn ở bước tiếp theo (được hiển thị trong hình 10.4) là rất ít mạnh hơn vì nó thiếu các kết nối hồi quy giữa các đơn vị ẩn. Ví dụ, nó không thể mô phỏng một máy Turing phổ dụng. Vì mạng này thiếu kết nối hồi quy giữa các đơn vị ẩn, nó đòi hỏi rằng các đơn vị đầu ra nắm bắt tất cả thông tin về quá khứ mà mạng sẽ sử dụng để dự đoán tương lai. Vì các đơn vị đầu ra được huấn luyện một cách rõ ràng để match với training set targets, chúng không thể nắm bắt các thông tin cần thiết về lịch sử quá khứ của đầu vào, trừ khi người dùng biết cách mô tả trạng thái đầy đủ của hệ thống và cung cấp nó như một phần của training set targets. Lợi thế của việc loại bỏ hidden-to-hidden recurrence, đối với bất kỳ hàm mất nào dựa trên so sánh các dự đoán với training target tại thời điểm t là tất cả các bước có thể được tách riêng. Sự huấn luyện do đó có thể thực hiện song song, với gradient cho mỗi bước t được tính toán độc lập. Không cần tính toán đầu ra cho bước trước, vì tập huấn luyện cung cấp giá trị lý tưởng của đầu ra đó.
 
Hình 10.5: Recurrent Neural Network thời gian mở với một đầu ra duy nhất ở cuối chuỗi. Một mạng như vậy có thể được sử dụng để tóm tắt một chuỗi và tạo ra một biểu diễn kích thước cố định được sử dụng làm đầu vào để xử lý tiếp. Có thể có một đích ở cuối (như được mô tả ở đây) hoặc gradient trên output o(t) có thể thu được bằng cách truyền lại từ các mô đun tiếp theo.
Các mô hình có kết nối hồi quy từ kết quả đầu ra của chúng dẫn trở lại mô hình có thể được huấn luyện với Teacher Forcing. Teacher Forcing là một thủ tục xuất hiện từ tiêu chí khả năng tối đa, trong quá trình training, mô hình nhận được mục tiêu đầu ra y(t) làm đầu vào tại thời điểm t + 1. Chúng ta có thể thấy điều này bằng cách kiểm tra một chuỗi với hai bước. Tiêu chi hợp lý cực đại có điều kiện là:
 
Trong ví dụ trên, chúng ta thấy rằng tại thời điểm t = 2, mô hình được huấn luyện để tối đa hóa xác suất có điều kiện của y(2) cho cả chuỗi x tính đến bước đang xét và giá trị y trước đó từ tập huấn luyện. Do đó, khả năng tối đa (maximum likelihood) chỉ định rằng trong quá trình training, thay vì cho đầu ra của chính mô hình trở lại chính nó, các kết nối này nên được cung cấp với các giá trị đích xác định đầu ra chính xác. Điều này được minh họa trong hình 10.6.
 
Hình 10.6: Minh họa Teacher Forcing. Teacher Forcing là một kỹ thuật huấn luyện áp dụng cho RNN có kết nối hồi quy từ đầu ra đến trạng thái ẩn ở bước tiếp theo. (bên Trái) Tại thời điểm training, chúng tôi cung cấp kết quả mục tiêu y(t) (target) được lấy từ bộ huấn luyện như đầu vào cho h(t +1). (bên Phải) Khi mô hình được triển khai, đầu ra thực sự thường không được biết. Trong trường hợp này, chúng ta ước lượng mục tiêu đầu ra y(t) với đầu ra của mô hình o(t) và đưa đầu ra trở lại vào mô hình.
Ban đầu chúng tôi dùng Teacher Forcing để tránh việc truyền lại qua thời gian trong các mô hình thiếu các kết nối ẩn giấu hidden-to-hidden. Teacher Forcing có thể vẫn được áp dụng cho các mô hình có các kết nối ẩn đến ẩn (hidden-to-hidden), miễn là chúng có các kết nối từ đầu ra tại một bước tới các giá trị được tính trong bước tiếp theo. Tuy nhiên, ngay sau khi các đơn vị ẩn trở thành một hàm của các bước trước đó, chúng ta sẽ cần dùng thuật toán lan truyền ngược liên hồi (BPTT). Một số mô hình do đó có thể được huấn luyện kết hợp Teacher Forcing và BPTT.
Những bất lợi của Teacher Forcing phát sinh nếu mạng sẽ được sử dụng sau này trong một chế độ vòng lặp mở (open-loop), với các đầu ra mạng được nạp lại như đầu vào. Trong trường hợp này, loại đầu vào trong quá trình huấn luyện có thể hoàn toàn khác với loại đầu vào mà nó sẽ thấy vào thời điểm kiểm định (test). Một cách để giảm thiểu vấn đề trên là huấn luyện với cả đầu vào do Teacher Forcing và các đầu vào tự do (free-running inputs), ví dụ bằng cách dự đoán mục tiêu chính xác một số bước trong tương lai thông qua các đường dẫn đầu vào-đầu ra (input-to-output) không hồi quy. Theo cách này, mạng có thể học xem xét các điều kiện đầu vào (chẳng hạn như những điều mà nó tự tạo ra trong chế độ tự do) không thấy trong quá trình trianing và cách ánh xạ trạng thái hướng tới trạng thái đầu ra sau vài bước. Một cách tiếp cận khác (Bengio et al., 2015b) để giảm thiểu khoảng cách giữa các đầu vào thời điểm training và thời điểm test ngẫu nhiên chọn sử dụng các giá trị được tạo ra hoặc các giá trị dữ liệu thực tế như đầu vào. Cách tiếp cận này khai thác một chiến lược học tập chương trình giảng dạy để dần dần sử dụng nhiều giá trị được tạo ra như đầu vào.
10.2.2. Tính toán Gradient trong một Recurrent Neural Network 
Tính toán gradient thông qua Recurrent Neural Network rất đơn giản. Chúng ta có thể áp dụng thuật toán back-propagation của phần 6.5.6 mà không cần thuật toán quá cao siêu. Gradients thu được bằng back-propagation sau đó có thể được sử dụng với bất kỳ kỹ thuật dựa trên gradient có mục đích chung để training một RNN.
Để đạt được một số trực giác về cách hoạt động của thuật toán BPTT, chúng tôi cung cấp một ví dụ về cách tính toán gradient bằng BPTT cho các phương trình RNN ở trên (phương trình 10.8 và phương trình 10.12). Các nút của mạch tính toán của chúng tôi bao gồm các tham số U, V, W, b và c cũng như chuỗi các nút phụ thuộc t cho x(t), h(t), o(t) và L(t). Đối với mỗi nút N, chúng ta cần tính toán gradient đệ quy ∇NL, dựa trên gradient được tính toán tại các nút theo sau nó trong mạch. Chúng ta bắt đầu đệ quy với các nút cuối cùng.
 
Trong đạo hàm này, chúng ta giả định rằng các đầu ra o(t) được sử dụng làm đối số cho hàm softmax để thu được vectơ ŷ của xác suất trên đầu ra. Chúng tôi cũng giả định rằng hàm mất mát là hàm âm log-likelihood của kết quả đúng y(t). Gradient ∇o(t)L của đầu ra tại bước t, qua tất cả i, t, như sau:
 
Ở bước cuối cùng, τ, h(τ) chỉ có o(τ) như một kết quả, do đó gradient của nó đơn giản:
 
Sau đó chúng ta truyền lại gradient theo từng bước, từ t = τ −1 về t = 1, lưu ý rằng h(t) (với t <τ) có dạng con cháu của o(t) và h(t). Do đó, gradient của nó được cho bởi
 
trong đó diag (1-(h(t+1))2) biểu thị ma trận đường chéo chứa các phần tử 1 – (hi(t+1))2. Nó là định thức Jacobian của tiếp tuyến hyperbol liên kết với unit i tại thời điểm t+1.
Khi thu được các gradient qua các đồ thị tính toán, chúng ta có thể có được các gradient trên các nút tham số. Bởi vì các tham số được chia sẻ qua nhiều bước, chúng ta phải cẩn thận khi biểu thị các phép toán liên quan đến các biến này. Các phương trình chúng tôi muốn thực hiện sử dụng phương pháp backpropagation của phần 6.5.6, tính toán sự đóng góp của một cạnh đơn trong mạch với gradient. Tuy nhiên, toán tử ∇W f được sử dụng trong phép tính tính đến sự đóng góp của W với giá trị của f do tất cả các cạnh trong mạch tính toán. Để nói rõ hơn, chúng tôi giả sử các biến giả W(t) được định nghĩa là bản sao của W nhưng với mỗi W(t) chỉ được sử dụng ở bước t. Sau đó, chúng tôi có thể sử dụng ∇W(t) để biểu thị sự đóng góp của các trọng số tại từng bước t góp phần vào gradient.



Ta có thể sử dụng ký hiệu này để biể thị gradient trên các tham số con lại như sau:
  
10.2.3. Recurrent Networks as Directed Graphical Models
Trong các ví dụ về Recurrent Network mà chúng ta đã nói cho đến nay, các giá trị mất mát L(t) là các cross-entropies (độ lệch giữa 2 phân bố xác suất) giữa các target y(t) và kết quả đầu ra o(t). Như với một mạng feedforward, về nguyên tắc có thể sử dụng hầu như bất kỳ hàm mất mát nào với Recurrent Network. Sự mất mát nên được lựa chọn dựa trên bài toán cụ thể. Như với một mạng feedforward, chúng ta thường muốn giải thích đầu ra của RNN như là một phân phối xác suất, và chúng ta thường sử dụng cross-entropy kết hợp với phân phối đó để xác định sự mất mát. Giá trị bình phương trung bình của mất mát là cross-entropy kết hợp với một phân bố đầu ra là một đơn vị Gaussian, ví dụ như với một mạng feedforward.
Khi chúng ta sử dụng một đối tượng huấn luyện dự đoán khả năng cao nhất, chẳng hạn như phương trình 10.12, chúng ta huấn luyện RNN để ước tính sự phân bố có điều kiện của phần tử tiếp theo y(t) cho các đầu vào trong quá khứ. Điều này có thể hiểu là chúng ta đi tối đa hóa hàm log-Likelihood
 
Hoặc, nếu mô hình bao gồm các kết nối từ đầu ra tại một bước tới bước tiếp theo,
	 
Phân tích xác suất chung trên chuỗi các giá trị y như một loạt các dự đoán xác suất từng bước là một cách để nắm bắt đầy đủ sự phân bố trên toàn bộ chuỗi. Khi chúng ta không nạp lại các giá trị y như các đầu vào có điều kiện để dự đoán bước tiếp theo, mô hình đồ thị định hướng không chứa các đường từ y(i) nào trong quá khứ đến y(t) hiện tại. Trong trường hợp này, các kết quả đầu ra y là độc lập với chuỗi giá trị x. Khi chúng ta nạp các giá trị y thực tế (không phải dự đoán của chúng, nhưng giá trị được quan sát hoặc tạo ra thực tế) trở lại vào mạng, mô hình đồ thị có hướng chứa các cạnh từ tất cả các giá trị y(i) trong quá khứ tới giá trị y(t) hiện tại.
Như một ví dụ đơn giản, chúng ta hãy xem xét trường hợp các mô hình RNN chỉ là một chuỗi các biến ngẫu nhiên vô hướng Y = {y(1),..., y(τ)}, không có đầu vào bổ sung x. Đầu vào tại bước t chỉ đơn giản là đầu ra ở bước t − 1. RNN sau đó định nghĩa một mô hình đồ thị có hướng qua các biến y. Chúng tôi phân tích sự phân bố chung của các quan sát này bằng cách sử dụng quy tắc chuỗi (chain rule) (phương trình 3.6) cho các xác suất có điều kiện:
 
trong đó vế phải của biểu thức rỗng cho t = 1, tất nhiên. Do đó, khả năng log-likelihood âm của một tập hợp các giá trị {y(1),..., y(τ)} theo mô hình như vậy
 
Hình 10.7: Mô hình đồ thị kết nối đầy đủ cho một chuỗi y(1), y(2),..., y(t),...: mỗi biến cố y(i) có thể ảnh hưởng đến phân phối có điều kiện của y(t) (đối với t> i. Việc mô tả trực tiếp mô hình đồ thị theo đồ thị này (như trong phương trình 10.6) có thể rất kém hiệu quả, với số lượng đầu vào và tham số ngày càng tăng cho từng phần tử của chuỗi. RNNs có được sự kết nối đầy đủ nhưng hiệu quả, như minh họa trong hình 10.8.
 
trong đó
 

 
Hình 10.8: Giới thiệu biến trạng thái trong mô hình đồ thị của RNN, mặc dù nó là hàm xác định các đầu vào của nó, giúp chúng ta biết làm thế nào để có được một tham số thật hiệu quả, dựa trên phương trình 10.5. Mỗi trạng thái trong chuỗi (đối với h(t) và y(t)) có cùng một cấu trúc (cùng số lượng đầu vào cho mỗi nút) và có thể chia sẻ cùng các tham số với các giai đoạn khác.
Các cạnh trong mô hình đồ thị cho biết sự phụ thuộc trực tiếp giữa các biến. Nhiều mô hình đồ thị nhắm đến việc đạt hiệu quả thống kê và tính toán bằng cách bỏ qua các cạnh không tương ứng với các tương tác mạnh. Ví dụ, thông thường cho các giả định Markov rằng mô hình đồ thị chỉ nên chứa các cạnh từ {y(t-k),..., y(t-1)} đến y(t), thay vì chứa các cạnh trong toàn bộ quá khứ. Tuy nhiên, trong một vài trường hợp, chúng ta tin rằng tất cả đầu vào trước đây nên có một ảnh hưởng đến phần tử tiếp theo trong chuỗi. RNN có ích khi chúng ta tin rằng sự phân bố trên y(t) có thể phụ thuộc vào giá trị y(i) từ quá khứ xa theo cách không bị ảnh hưởng bởi y(i) trên y(t-1).
Một cách để giải thích RNN giống một mô hình đồ thị là xem RNN như định nghĩa một mô hình đồ đầy đủ, có thể biểu diễn trực tiếp các phụ thuộc giữa bất kỳ cặp giá trị y nào. Mô hình đồ thị trên các giá trị y với cấu trúc đồ thị đầy đủ được thể hiện trong hình 10.7. Việc giải thích đồ thị đầy đủ của RNN dựa trên việc bỏ qua các đơn vị ẩn h(t) bằng cách tách chúng ra khỏi mô hình.
Điều thú vị hơn là xem xét cấu trúc mô hình đồ thị của RNNs rút ra từ việc coi các đơn vị ẩn h(t) như các biến ngẫu nhiên. Bao gồm các đơn vị ẩn trong mô hình đồ thị cho thấy rằng RNN cung cấp một tham số hoá rất hiệu quả của sự phân phối chung trên các quan sát. Giả sử rằng chúng ta biểu diễn một phân phối chung tùy ý trên các giá trị rời rạc với dạng bảng - một mảng chứa một mục riêng cho mỗi phép gán có thể có giá trị, với giá trị của mục đó cho xác suất của phép gán đó xảy ra. Nếu y có thể nhận k giá trị khác nhau, bảng biểu diễn sẽ có O(kτ) tham số. Bằng so sánh, nhờ chia sẻ tham số nên số lượng tham số trong RNN là O(1) như một hàm của chiều dài chuỗi. Số lượng tham số trong RNN có thể được điều chỉnh để điều khiển sức chứa của mô hình mà không bị buộc phải mở rộng theo chiều dài chuỗi. Phương trình 10.5 cho thấy rằng RNN parametrizes 10.5 quan hệ lâu dài giữa các biến một cách hiệu quả, sử dụng các ứng dụng hồi quy của cùng một hàm f và cùng các tham số θ ở mỗi bước. Hình 10.8 minh họa cách giải thích mô hình đồ thị. Kết hợp các nút h(t) trong mô hình đồ thị tách rời quá khứ và tương lai, hoạt động như một số lượng trung gian giữa chúng. Một biến y(i) trong quá khứ xa có thể ảnh hưởng đến biến y(t) thông qua tác động của nó trên h. Cấu trúc của đồ thị này cho thấy mô hình có thể được tham số hiệu quả bằng cách sử dụng cùng phân bố xác suất có điều kiện ở mỗi bước, và khi tất cả các biến được quan sát, xác suất của phép gán chung của tất cả các biến có thể được đánh giá một cách hiệu quả.
1 Sự phân bố có điều kiện đối với các biến này cho cha mẹ của chúng là xác định. Điều này là hoàn toàn hợp pháp, mặc dù nó là hơi hiếm để thiết kế một mô hình đồ thị với các đơn vị ẩn xác định như vậy.
Ngay cả với tham số hoá hiệu quả của mô hình đồ thị, một số hoạt động tính toán còn khó khăn. Ví dụ, rất khó để dự đoán các giá trị còn thiếu ở giữa chuỗi.

Cái giá mà các mạng hồi quy trả cho số lượng tham số giảm của chúng là việc tối ưu hóa các tham số có thể khó khăn.

Việc chia sẻ tham số sử dụng trong mạng hồi quy phụ thuộc vào giả định rằng với cùng tham số có thể được sử dụng cho các bước khác nhau. Tương đương, giả định rằng phân bố xác suất có điều kiện trên các biến tại thời điểm t + 1 cho các biến tại thời điểm t là không đổi, có nghĩa là mối quan hệ giữa bước trước đó và bước tiếp theo không phụ thuộc vào t. Về nguyên tắc, có thể sử dụng t làm đầu vào bổ sung ở mỗi bước và cho phép người học khám phá bất kỳ sự phụ thuộc thời gian nào trong khi chia sẻ nhiều nhất có thể giữa các bước khác nhau. Điều này sẽ tốt hơn nhiều so với việc sử dụng phân bố xác suất có điều kiện khác nhau cho mỗi t, nhưng mạng sau đó sẽ phải ngoại suy khi đối mặt với các giá trị mới của t.
Để hoàn thành cái nhìn của chúng ta về một RNN như một mô hình đồ thị, chúng ta phải mô tả cách vẽ các mẫu từ mô hình. Hoạt động chính mà chúng ta cần thực hiện đơn giản là lấy mẫu từ phân phối có điều kiện ở mỗi bước thời gian. Tuy nhiên, có thêm một vấn đề. RNN phải có một vài cơ chế để xác định chiều dài chuỗi. Vấn đề này có thể giải quyết bằng nhiều cách.
Trong trường hợp đầu ra là một ký hiệu được lấy từ một từ vựng, người ta có thể thêm một ký hiệu đặc biệt tương ứng với phần cuối của một chuỗi (Schmidhuber, 2012). Khi ký hiệu được tạo ra, quá trình lấy mẫu dừng lại. Trong tập huấn luyện, chúng ta chèn ký hiệu này như một thành viên bổ sung của chuỗi, ngay sau x(τ) trong mỗi ví dụ huấn luyện.
Một lựa chọn khác là giới thiệu đầu ra thêm Bernoulli cho mô hình biểu diễn cho quyết định tiếp tục thế hệ hoặc tạm dừng thế hệ tại mỗi bước thời gian. Cách tiếp cận này tổng quát hơn cách tiếp cận thêm một ký hiệu bổ sung vào từ vựng, bởi vì nó có thể được áp dụng cho bất kỳ RNN nào, thay vì chỉ các RNN tạo ra một chuỗi ký hiệu. Ví dụ, nó có thể áp dụng cho mộ RNN phát ra một chuỗi các số thực. Đơn vị đầu ra mới thường là một đơn vị sigmoid được huấn luyện với sự mất mát cross-entropy. Trong cách tiếp cận này, sigmoid được huấn luyện để tối đa hóa khả năng log của dự đoán chính xác về việc chuỗi kết thúc hay tiếp tục ở mỗi bước thời gian.

Một cách khác để xác định độ dài chuỗi τ là thêm đầu ra phụ vào mô hình tự nó dự đoán chính số nguyên τ. Các mô hình có thể lấy mẫu một giá trị của τ và sau đó mẫu τ các bước giá trị của dữ liệu. Cách tiếp cận này yêu cầu thêm đầu vào bổ sung cho cập nhật hồi quy ở từng bước để cập nhật hồi quy nhận thức được liệu nó có gần cuối chuỗi được tạo hay không. Đầu vào thêm này hoặc có thể bao gồm các giá trị của τ hoặc có thể bao gồm τ−t, số lượng các bước thời gian còn lại. Nếu không có đầu vào bổ sung này, RNN có thể tạo ra các chuỗi kết thúc bất ngờ, chẳng hạn như một câu kết thúc trước khi nó được hoàn tất. Cách tiếp cận này được dựa trên công thức.
 
Chiến lược dự đoán trực tiếp τ được sử dụng cho ví dụ bởi Goodfellow et al. (2014d).
	
10.2.4. Mô hình trình tự có điều kiện trên bối cảnh với Recurrent Neural Networks
Trong phần trước chúng ta đã mô tả cách một RNN có thể tương ứng với một mô hình đồ thị có hướng qua một chuỗi các biến ngẫu nhiên y(t) mà không có đầu vào x. Tất nhiên, sự phát triển của các RNN như trong phương trình 10.8 bao gồm một chuỗi các đầu vào x(1), x(2),... , x(τ). Nói chung, RNNs cho phép mở rộng cách nhìn mô hình đồ thị để biểu diễn không chỉ một phép phân phối chung trên các biến y mà còn là phân phối có điều kiện so với y đã cho x. Như đã thảo luận, trong bối cảnh của các mạng feedforward trong phần 6.2.1.1, bất kỳ mô hình nào đại diện cho biến P(y; θ) có thể được diễn giải lại như một mô hình đại diện cho phân phối có điều kiện P(y | ω) với ω = θ. Chúng ta có thể mở rộng mô hình như vậy để biểu diễn một phân bố P(y | x) bằng cách sử dụng cùng một P(y | ω) như trước, nhưng cho ω một hàm của x. Trong trường hợp của RNN, điều này có thể đạt được theo nhiều cách khác nhau. Chúng tôi xem xét ở đây những lựa chọn phổ biến nhất và rõ ràng nhất.
Trước đây, chúng ta đã thảo luận RNNs lấy một chuỗi các vectơ x(t) cho t = 1,... , τ làm đầu vào. Một tùy chọn khác là chỉ lấy một vector x làm đầu vào. Khi x là một vector có kích thước cố định, chúng ta đơn giản có thể cho nó làm một đầu vào thêm của RNN để tạo ra chuỗi y. Một số cách phổ biến để cung cấp thêm đầu vào cho RNN là:
1. Như một đầu vào bổ sung tại mỗi bước
2. Như trạng thái khởi tạo h(0)
3. Cả hai cách trên.
Cách tiếp cận đầu tiên và phổ biến nhất được minh họa trong hình 10.9. Sự tương tác giữa đầu vào x và mỗi vector đơn vị ẩn h(t) được tham số hóa bởi một ma trận trọng số R mới được giới thiệu không có trong mô hình chỉ có chuỗi các giá trị y. Cùng một tích xTR được thêm vào như một đầu vào bổ sung cho các đơn vị ẩn tại mỗi bước. Chúng ta có thể nghĩ về sự lựa chọn của x khi xác định giá trị của xTR, đó là một tham số thiên vị (bias) mới được sử dụng cho mỗi đơn vị ẩn. Các trọng số vẫn độc lập với đầu vào. Chúng ta có thể nghĩ về mô hình này khi lấy các tham số θ của mô hình phi điều kiện và biến chúng thành ω, với các tham số thiên vị (bias) trong ω bây giờ là một hàm của đầu vào.
 
Hình 10.9: Một RNN ánh xạ một vectơ có độ dài cố định thành phân bố theo dãy Y. RNN này thích hợp cho các tác vụ như chú thích hình ảnh, trong đó một hình ảnh được sử dụng làm đầu vào cho một mô hình, sau đó tạo ra một chuỗi các từ mô tả hình ảnh. Mỗi phần tử y(t) của chuỗi đầu ra đóng vai trò là đầu vào (cho bước hiện tại) và trong quá trình đào tạo, làm mục tiêu (cho bước trước đó).
Thay vì chỉ nhận được một vector x làm đầu vào, RNN có thể nhận được một chuỗi các vectơ x(t) làm đầu vào. RNN được mô tả trong phương trình 10.8 tương ứng với sự phân bố có điều kiện P (y(1),.,., y(τ) | x(1),.., x(τ)) tạo ra một giả định độc lập có điều kiện rằng phân phối này có yếu tố như:
 
Để loại bỏ giả định độc lập có điều kiện, chúng ta có thể thêm các kết nối từ đầu ra tại thời điểm t tới đơn vị ẩn tại thời điểm t + 1, như trong hình 10.10. Sau đó, mô hình có thể biểu diễn các phân bố xác suất tùy ý trong chuỗi y. Loại mô hình này thể hiện sự phân bố theo trình tự được cho một chuỗi khác vẫn có một hạn chế, đó là độ dài của cả hai trình tự phải giống nhau. Chúng tôi sẽ mô tả cách xóa giới hạn này trong phần 10.4.
 
Hình 10.10: Mạng nơ-ron hồi quy có điều kiện ánh xạ một chuỗi các giá trị x có độ dài biến đổi thành một phân bố trên dãy các giá trị y có cùng độ dài. So với hình 10.3, RNN này chứa thêm các kết nối từ đầu ra trước đó tới trạng thái hiện tại. Các kết nối này cho phép RNN mô hình hóa sự phân bố tùy ý theo các trình tự của các chuỗi x có cùng độ dài. RNN của hình 10.3 chỉ có thể biểu diễn các phân phối trong đó các giá trị y có điều kiện độc lập với nhau cho bởi các giá trị x.
 
Hình 10.11: Một mạng nơron hồi quy hai chiều điển hình, có nghĩa là ánh xạ các chuỗi đầu vào x đến các chuỗi mục tiêu y, với mất mát L(t) ở mỗi bước t. Sự lặp lại h lan truyền thông tin về phía trước theo thời gian (về phía bên phải) trong khi g lặp lại thông tin ngược thời gian (về phía bên trái). Vì vậy, tại mỗi bước t, các đơn vị đầu ra o(t) có thể hưởng lợi từ một bản tóm tắt có liên quan của quá khứ trong đầu vào h(t) và từ một bản tóm tắt có liên quan về tương lai trong đầu vào g(t) của nó.

10.3. Bidirectional RNNs (mạng nơron hồi quy 2 chiều) 
Tất cả các recurrent networks mà chúng ta đã xem xét đến nay đều có cấu trúc "nhân quả", có nghĩa là trạng thái tại thời điểm t chỉ thu thập thông tin từ quá khứ, x(1),... , x (t − 1) và đầu vào hiện tại x (t). Một số mô hình chúng tôi đã thảo luận cũng cho phép thông tin từ các giá trị y trong quá khứ cũng ảnh hưởng đến trạng thái hiện tại khi y là giá trị có sẵn.
	Tuy nhiên, trong nhiều ứng dụng, chúng tôi đưa ra dự đoán của y(t) có thể phụ thuộc vào toàn bộ chuỗi đầu vào. Ví dụ, trong nhận dạng giọng nói, chính xác việc giải thích âm thanh hiện tại như một âm sắc có thể phụ thuộc vào âm sắc kế tiếp do trùng khớp và còn có thể phụ thuộc vào một số từ do phụ thuộc ngôn ngữ giữa các từ lân cận (linking sound – nối âm) : nếu có là hai cách giải thích của từ hiện tại vừa hợp lý về mặt âm thanh, chúng ta có thể phải nhìn xa vào tương lai (và quá khứ) để phân biệt chúng. Điều này cũng đúng với nhận dạng chữ viết tay và nhiều tác vụ học tuần tự khác, sẽ mô tả trong phần tiếp theo
Các mạng nơron hồi quy hai chiều (các RNN hai chiều) được phát minh để giải quyết nhu cầu đó (Schuster và Paliwal, 1997). Họ đã rất thành công (Graves, 2012) trong các ứng dụng thực tiễn, chẳng hạn như nhận dang chữ viết tay (Graves và cộng sự, 2008; Graves và Schmidhuber, 2009), nhận dạng giọng nói (Graves và Schmidhuber, 2005; Graves và cộng sự, 2013) và tin sinh học (Baldi) et al., 1999).
Cái tên nói lên tất cả, RNN hai chiều kết hợp một RNN di chuyển về phía trước xuất phát ở đầu trình tự với một RNN khác di chuyển ngược xuất phát từ cuối trình tự. Hình 10.11 minh họa RNN hai chiều điển hình, với h(t) đại diện cho trạng thái của sub-RNN di chuyển xuôi thời gian và g(t) đại diện cho trạng thái của sub-RNN di chuyển ngược thời gian. Điều này cho phép các đơn vị đầu ra o(t) tính toán một biểu diễn phụ thuộc vào cả quá khứ và tương lai nhưng lại nhạy cảm với các input trong khoảng thời gian t, mà không phải chỉ rõ 1 fixed-size window lân cận thời điểm t (giống như một trong những bước sẽ phải làm với một mạng feedforward, một mạng chuyển đổi, hoặc một RNN thông thường với một bộ đệm có kích thước cố định). 
Ý tưởng này có thể được mở rộng theo cách tự nhiên thành một đầu vào 2 chiều, ví dụ như hình ảnh, bởi có bốn RNN, mỗi người đi theo một trong bốn hướng: lên, xuống, trái, phải. Tại mỗi điểm (i, j) của không gian 2D, một đầu ra Oi,j có thể tính toán đâu sẽ là đại diện nắm bắt hầu hết thông tin cục bộ nhưng cũng có thể phụ thuộc phạm vi đầu vào, điều đó là khả thi nếu RNN có thể học cách chắt lọc thông tin đó. So với convolutional network, RNN được áp dụng cho hình ảnh thường là tốn kém hơn nhưng cho phép tương tác tầm xa giữa các tính năng trong cùng một bản đồ đặc trưng (Visin và cộng sự, 2015; Kalchbrenner và cộng sự, 2015). Thật vậy, các phương trình forward propagation cho các RNN như vậy có thể viết được dưới dạng hiển thị, họ sử dụng tích chập đầu vào từ dưới lên cho mỗi lớp, ưu tiên lan truyền hồi quy trên bản đồ đặc trưng kết hợp với những tương tác xung quanh.

10.4. Encoder-Decoder Sequence-to-Sequence Archiectures (kiến trúc mã hóa-giải mã tuần tự) 
Chúng ta đã thấy trong hình 10.5 cách RNN có thể ánh xạ một chuỗi đầu vào đến một vector có kích thước cố định, và trong hình 10.9 cách RNN có thể ánh xạ một vector có kích thước cố định đến một trình tự. Chúng ta lại thấy trong các hình 10.3, 10.4, 10.10 và 10.11 cách RNN có thể ánh xạ một chuỗi đầu vào đến một chuỗi đầu ra có cùng độ dài.
 (10.12)
Hình 10.12: Ví dụ về giải mã-mã hóa hoặc kiến trúc tuần tự RNN cho việc học để tạo ra một chuỗi đầu ra (y(1),.., y (n y)) được cho bởi một chuỗi đầu vào (x(1), x (2),.,., x (nx)). Nó bao gồm một bộ mã hóa RNN đọc chuỗi đầu vào và bộ giải mã RNN tạo chuỗi đầu ra (hoặc tính toán xác suất của chuỗi output định trước). Trạng thái ẩn cuối cùng của bộ mã hóa RNN được sử dụng để tính toán khái quát kích thước ngữ cảnh của 1 biến C đại diện cho một bản tóm tắt ngữ nghĩa của input trình tự và được làm đầu vào cho bộ giải mã RNN. 
Ở đây chúng ta thảo luận về một RNN có thể được training để ánh xạ một chuỗi đầu vào đến một chuỗi đầu ra không nhất thiết phải có cùng độ dài. Điều này xuất hiện trong nhiều ứng dụng, chẳng hạn như nhận dạng giọng nói, dịch máy hoặc trả lời câu hỏi, nơi các chuỗi đầu vào và đầu ra trong tập huấn luyện nói chung không cùng chiều dài (mặc dù độ dài của chúng có thể liên quan).
Chúng ta thường gọi đầu vào của RNN là "ngữ cảnh". Chúng ta muốn tạo ra đại diện của ngữ cảnh này, đó là C. Ngữ cảnh C có thể là một vectơ hoặc chuỗi vectơ tóm tắt chuỗi đầu vào X = (x(1),..., x (nx)). Kiến trúc RNN đơn giản nhất để ánh xạ một chuỗi có độ dài biến thiên trình tự này - một chuỗi có độ dài biến thiên trình tự khác được đề xuất bởi Cho et al. (2014a) và ngay sau đó Sutskever et al. (2014) đã phát triển độc lập kiến trúc này và là người đầu tiên làm được dịch thuật tiên tiến bằng cách sử dụng phương pháp này. Hệ thống cũ dựa trên các đề xuất chấm điểm do một máy khác tạo ra chương trình dịch thuật, trong khi hệ thống mới sau này sử dụng một mạng hồi quy độc lập để tạo ra bản dịch. Các tác giả ấy được đặt tên cho kiến trúc này, được minh họa trong hình 10.12, bộ giải mã-mã hóa hoặc cấu trúc trình tự liên tiếp. Các ý tưởng rất đơn giản: 
(1) một bộ mã hóa hoặc người đọc hoặc đầu vào RNN xử lý input trình tự. Bộ mã hóa tạo ra ngữ cảnh C, thường là một hàm đơn giản ở trạng thái ẩn tại ca làm việc cuối cùng. 
(2) một bộ giải mã hoặc nhà văn hoặc đầu ra RNN được điều chỉnh bằng vector có độ dài cố định (giống như trong hình 10.9) để tạo ra chuỗi đầu ra Y = (y(1),.., Y (ny)). 
Sự đổi mới của loại kiến trúc này so với kiến trúc cũ trình bày trong phần trước của chương này là độ dài nx và ny có thể khác nhau, trong khi kiến trúc trước đó bị hạn chế nx = ny = τ. Trong một kiến trúc tuần tự, hai RNN được đào tạo song song để tối đa hóa 1 cách trung bình của bản ghi P (y(1),.,., y (ny) | x(1),.., x (nx)) trên tất cả các cặp x và y trình tự trong tập huấn luyện. trạng thái cuối cùng hnx của bộ mã hóa RNN thường được coi là một đại diện C của một tập các chuỗi đầu vào, nó đóng vai trì là đầu vào cho bộ giải mã RNN. 
Nếu ngữ cảnh C là một véc-tơ, thì bộ giải mã RNN đơn giản chỉ là một RNN ánh xạ vectơ-vector như được mô tả trong phần 10.2.4. Như chúng ta đã thấy, có ít nhất hai cách cho RNN nhận đầu vào là vector. Đầu vào có thể được cung cấp là trạng thái ban đầu của RNN, hoặc đầu vào có thể được kết nối với các đơn vị ẩn tại mỗi bước thời gian. Hai cách này cũng có thể được kết hợp với nhau. 
Không có ràng buộc rằng bộ mã hóa phải có cùng kích thước của lớp ẩn như bộ giải mã. 
Một giới hạn dễ thấy của kiến trúc này là khi ngữ cảnh C tạo ra bởi bộ mã hóa RNN có kích thước quá nhỏ để tóm tắt các chuỗi trình tự. Hiện tượng này được quan sát bởi Bahdanau et al. (2015) trong bối cảnh dịch máy. Họ đề xuất biến C thành một chuỗi có độ dài thay đổi sẽ tốt hơn là một vector có kích thước cố định. Ngoài ra, họ đã giới thiệu một attention mechanism (cơ chế chú ý) học cách liên kết các phần tử của chuỗi C với các phần tử của đầu ra. Xem phần 12.4.5.1 để biết thêm chi tiết.
10.5. Deep Reccurent Networks: Mạng hồi quy sâu
Học sâu được xây dựng dựa trên một giả thuyết rằng một mô hình phân cấp sâu có thể hiệu quả hơn cấp số nhân lần so với mô hình nông trong việc biểu diễn các hàm (Bengio, 2009). Rất nhiều kết quả thực nghiệm gần đây ủng hộ giả thuyết này (e.g., Le Roux and Bengio, 2010; Delalleau and Bengio, 2011; Pascanu et al., 2013b). Những phát hiện này khiến chúng ta nghĩ đến việc áp dụng lập luận tương tự cho các mạng thần kinh hồi quy.
10.5.1. Computation: Sự tính toán
Sự tính toán trong hầu hết các mạng noron hồi quy có thể được chia thành 3 khối tham số cùng các phép biến đổi liên quan:
	Từ input đến hidden state (trạng thái ẩn): x^t → h^t
	Từ hidden state trước đến hidden state tiếp theo: h^(t-1) 〖 →h〗^t
	Từ hidden state đến output: h^t →o^t
Với kiến trúc RNN trong hình 10.3, mỗi khối được liên kết với nhau bằng một ma trận trọng số duy nhất. Nói cách khác khi mạng được khai triển (unfolded) theo thời gian mỗi phép biến đổi tương ứng với 1 phép biến đổi shallow. (Mỗi hình vuông đen tương ứng với một trễ thời gian từ trạng thái thời gian t đến t+1). Phép biến đổi nông (shallow transformation) có nghĩa là nó được biểu diễn bởi 1 layer duy nhất trong một MLP sâu (Multi-layer Perceptron) – mạng nơron nhiều tầng. Thông thường, nó được học bởi các phép biến đổi affine (phi tuyến tính cố định) như các hàm tanh, sigmoid, …
Vậy có thuận lợi gì trong việc đưa chiều sâu vào mỗi phép toán ấy? Căn cứ vào các kết quả thực nghiệm (Graves et al., 2013; Pascanu et al., 2014a) cho thấy việc này rất cần thiết. Cũng như họ đồng ý với ý tưởng rằng chúng ta cần đủ chiều sâu để thực hiện các ánh xạ cần thiết.
10.5.2. Các kiểu mạng RNNs sâu

 

Hình 10.13: Một mạng hồi quy có thể trở thành sâu với các cách khác nhau. (a) Trạng thái ẩn hồi quy (Hidden recurrent state) có thể được chia thành các nhóm phân theo cấp bậc. (b) Tính toán sâu hơn có thể đưa vào trong đầu vào ẩn (input-hidden), các phần ẩn (hidden-hidden), đầu ra ẩn (hidden-output). Điều này có thể kéo dài đường đi ngắn nhất liên kết các bước thời gian khác nhau. (c)Có thể giảm sự kéo dài đường đi bằng cách đưa vào các kết nối bước nhảy (skip connections). 
Graves et al. (2013) là người đầu tiên đưa ra lợi ích đặc biệt của việc phân trạng thái của một RNN thành nhiều layer như hình 10.13. Chúng ta có thể hiểu là ở mức độ thấp hơn (layer dưới) trong hình 10.13a biến đổi đầu vào thô thành các biểu diễn thích hợp hơn đưa vào layer trên (mức độ cao). Tại mỗi hidden layer đều nhận đầu vào từ layer bên dưới và chính nó tại bước thời gian trước.
Tiếp đó, Pascanu et al. (2014a) đề xuất có một MLP (có thể sâu) riêng cho mỗi một trong ba khối liệt kê ở trên, như minh hoạ trong hình 10.13b. Nghĩa là ta sẽ đi qua một vài bước trung gian nữa. Do đó, cần phân bổ đủ bộ nhớ cho mỗi khối này. Bởi vậy việc thêm chiều sâu có thể khiến việc tối ưu phức tạp hơn. Nhưng nhìn chung nó dễ hơn việc tối ưu kiến trúc nông. Ở hình 10.13b, thời gian biến đổi ngắn nhất của 1 biến từ bước thời gian t thành biến trong bước thời gian t+1 trở nên lâu hơn. Ví dụ, nếu một MLP với 1 lớp ẩn được sử dụng trong chuyển trạng thái đến trạng thái, chúng ta đã gấp đôi chiều dài đường đi ngắn nhất giữa 2 biến trong hai bước thời gian bất kỳ so với mạng RNN cơ bản trong hình 10.3. Tuy nhiên, như lập luận của Pascanu et al. (2014a) sự kéo dài trên có thể được giảm đi nhờ thêm các kết nối bước nhảy trong đường đi hidden-to-hidden, như minh hoạ ở hình 10.13c. Hình 10.13c kết hợp skip-connection để đi thẳng đến bước thời gian tiếp theo mà không đi qua các bước trung gian nếu thoả mãn điều kiện nào đó.
















10.6. Recursive Neural Netwoks: Mạng nơron đệ quy
Là khái quát hóa mạng hồi quy thành một kiểu biểu đồ tính toán khác. Được cấu trúc như một cây sâu thay vì cấu trúc như một chuỗi trong mạng RNNs. Đồ thị tính toán điển hình được minh hoạ trong hình 10.14. Mạng đệ quy được giới thiệu bởi Pollack (1990) và mô tả tiềm năng của nó trong học máy bởi Bottou (2011). Mạng đệ quy đã được áp dụng thành công trong việc xử lý cấu trúc dữ liệu như đầu vào cho mạng thần kinh (Frasconi et al., 1997,1998), trong xử lý ngôn ngữ tự nhiên (Socher et al., 2011a.c. 2013a) cũng như trong thị giác máy (Socher et al., 2011b).
10.6.1 Đồ thị tính toán của mạng đệ quy


Hình 10.14: Một mạng đệ quy có đồ thị tính toán là dạng khái quát hóa 1 mạng hồi quy từ 1 chuỗi thành 1 cây. Một chuỗi các biến x^((1)), x^((2)),…, x^((t)) có thể được ánh xạ tới 1 biểu diễn cố định (output o), bằng 1 tập cố định các tham số cố định (ma trận trọng số U, V, W). Hình minh họa trường hợp học máy giám sát trong đó mục tiêu y với điều kiện là được liên kết với toàn bộ chuỗi.
Một ưu điểm rõ ràng của mạng đệ quy so với mạng hồi quy là với cùng 1 chuỗi có độ dài τ, độ sâu (được đo bằng số lượng của các phép toán phi tuyến tính thành phần) có thể giảm từ τ đến O (log τ), giúp giải quyết các phụ thuộc xa. Có thể hiểu đơn giản khi kết hợp 2 nút lá thành một nút nhánh dần dần tra giảm độ dài chuỗi đi hệ số 2 lần. Nên nó phù hợp trong học các cấu trúc phân cấp và dạng cây. Một câu hỏi mở là cách tốt nhất để cấu trúc cây.
10.6.2. Cấu trúc cây trong mạng đệ quy
Cấu trúc cây không phụ thuộc vào dữ liệu là cây nhị phân cân bằng. Trong một số miền ứng dụng, các phương pháp bên ngoài có thể đề xuất cấu trúc cây thích hợp. Ví dụ, khi xử lý các câu tự nhiên, cấu trúc cây cho mạng đệ quy có thể cố định là cấu trúc cây phân tích cú pháp câu của người phân tích cú pháp ngôn ngữ tự nhiên.
Lý tưởng nhất, người ta muốn người học tự khám phá và tìm ra cấu trúc cây thích hợp nhất cho bất kỳ đầu vào cụ thể nào.
10.6.3. Biến thể của mạng đệ quy
Nhiều ý tưởng về biến thể của mạng đệ quy là có thể. Chẳng hạn, Frasconi et al. (1997) và Frasconi et al. (1998) kết hợp dữ liệu với cấu trúc cây và kết hợp đầu vào, mục tiêu vào các nốt của cùng một cây. Tính toán thực hiện cho mỗi nốt không cần phải là tính toán nơ ron nhân tạo (biến đổi affine mà tất cả các đầu vào tuân theo một phi tuyến tính đơn điệu).
Ví dụ, Socher et al. (2013a) sử dụng phép toán tensor và kiểu song tuyến mà trước đây đã dùng được trong viêc mô hình các mối quan hệ giữa các quan niệm khi chúng được biểu diễn bằng vecto liên tục (các phần tử nhúng).




10.7. Thách thức của phụ thuộc xa
10.7.1. Giới thiệu
Tối ưu hóa mạng nơ ron gặp khó khăn khi đồ thị tính toán trở nên sâu, ví dụ:
	Mạng feedforward có nhiều layer
	RNNs mà liên tục áp dụng cùng một phép toán ở tất cả các bước thời gian trong chuỗi thời gian dài.
 Thách thức về mặt toán học của việc học phụ thuộc xa trong mạng hồi quy đã được trình bày ở phần 8.2.5. Vấn đề cơ bản là gradien lan truyền qua nhiều giai đoạn có xu hướng hoặc biến mất (phần lớn thời gian) hoặc phát nổ (gây thiệt hại hơn cho việc tối ưu). Ngay cả khi giả định rằng có các tham số sao cho mạng hồi quy là ổn định (có thể lưu đủ bộ nhớ và gradient không phát nổ) thì khó khăn với phụ thuộc xa phát sinh từ các trọng số nhỏ hơn theo cấp số nhân cho các tương tác dài hạn (liên quan đến các phép nhân nhiều Jacobians) so với các tương tác ngắn. Trong phần này, chúng ta mô tả vấn đề chi tiết hon. Các phần sau sẽ mô tả các cách tiếpp cận để khắc phục vấn đề.
10.7.2. Các hàm thành phần trong RNNs
Mạng hồi quy liên quan đến các thành phần của cùng một hàm nhiều lần, mỗi lần trên một bước thời gian. Các thành phần ấy có kết quả cực phi tuyến, như minh hoạ trong hình 10.15. 
 

Hình 10.15: Khi tập hợp nhiều hàm phi tuyến tính (như layer tuyến tính tanh được hiển thị ở đây), kết quả là phi tuyến tính cao, thường là các giá trị với đạo hàm nhỏ, một vài giá trị có đạo hàm lớn và có nhiều sự xen kẽ giữa tăng và giảm. Trong đồ thị này, chúng tôi vẽ một phép chiếu tuyến tính của 1 trạng thái ẩn 100 chiều xuống một chiều, biểu diễn trên trục y. Trục x là trục tọa độ của trạng thái ban đầu dọc theo hướng ngẫu nhiên trong không gian 100 chiều. Do đó, có thể xem đồ thị như 1 mặt cắt tuyến tính của 1 hàm high-dimensional(số chiều cao).Đồ thị cho thấy hàm sau mỗi bước thời gian hoặc tương đương với sau mỗi lần hàm chuyển tiếp được tạo thành. 
Trong đồ thị 10.15, ta sử dụng mạng nơron chỉ có một biến đầu vào x (trục x) và một vài hidden unit để cho ra 1 output. Các biến đầu ra ấy được đưa trở lại vào làm input và thực hiện việc này một số lần khác nhau. Hàm của x là những gì xảy ra mỗi lần chạy sau các bước thời gian. Đường thẳng màu xanh dương biểu diễn hàm khi chạy lần đầu tiên (không có vòng lặp)
Đặc biệt, việc sử dụng các hàm thành phần trong RNNs gần giống phép nhân ma trận. Chúng ta có thể hiểu mối quan hệ hồi quy 
 					(10.36)
như một RNNs đơn giản mà thiếu hàm kích hoạt phi tuyến và đầu vào x

Như đã trình bày ở phần 8.2.5, mối quan hệ hồi quy này chủ yếu mô tả power method (tìm ra giá trị riêng lớn nhất). Nó có thể được rút gọn như sau:
 				(10.37)
Trong đó nếu W có thể chéo hóa trực giao được
 					(10.38)
Với ma trận trực giao Q, khi đó công thức trở thành:
 				(10.39)
Giá trị riêng tăng tới giá trị t dẫn đến các giá trị riêng với độ lớn nhỏ hơn 1 giảm xuống 0 và các giá trị riêng có độ lớn lớn hơn 1 tăng đột biến. Bấy kỳ thành phần của h^((0)) mà không cùng hướng với vecto riêng lớn nhất sẽ bị loại bỏ.
10.7.3. Trường hợp vô hướng và giải pháp khả thi
Trong trường hợp vô hướng, tưởng tượng nhân trọng số w với chính nó nhiều lần. Khi đó   sẽ hoặc tiêu biến hoặc đột biến tùy thuộc vào độ lớn của w. Tuy nhiên, nếu chúng ta tạo một mạng không hồi quy có trọng số   khác nhau ở mỗi bước thời gian thì có trạng thái khác. Nếu trạng thái đầu vào là 1 thì trạng thái tại thời điểm t là  .
Nếu các giá trị  được tạo ngẫu nhiên, độc lập với kỳ vọng bằng không và phương sai v khi đó phương sai của tích là
Để đạt được phương sai  mong muốn chúng ta chọn riêng từng trọng số với phương sai. Từ đó tránh được vấn đề tiêu biến và bùng nổ gradien trong các mạng deep feedforward, như lập luận của Sussillo (2014).
10.7.4. Vấn đề tiêu biến và bùng nổ gradien: Vanishing and Exploding Gradient Problem
Vấn đề tiêu biến và bùng nổ gradien được phát hiện độc lập bởi 2 nhà nghiên cứu (Hochreiter, 1991; Bengio et al., 1993, 1994).
Người ta kỳ vọng vấn đề có thể giải quyết đơn giản bằng cách ở trong giới hạn của không gian tham số mà không xảy ra tiêu biến hoặc bùng nổ gradien. Nhưng để lưu trữ dữ liệu một cách mạnh mẽ cho những sự nhiễu nhỏ, RNN phải đi vào vùng không gian có tiêu biến gradien. Đặc biệt, bất cứ khi nào mô hình có thể biểu diễn phụ thuộc dài, độ lớn của gradien nhỏ hơn theo cấp số nhân so với tương tác ngắn.
Nó không có nghĩa là hoàn toàn không thể học được nhưng sẽ mất rất nhiều thời gian bởi tín hiệu về các phụ thuộc này sẽ bị ẩn đi bởi các dao động nhỏ nhất phát sinh từ phụ thuộc ngắn.
Trong thực tế, các nhà nghiên cứu cho thấy khi tăng vùng phụ thuộc mà cần thu nhập, tối ưu hóa dựa trên gradien trở nên ngày càng khó khăn, với khả năng đào tạo thành công một RNN truyền thống thông qua SGD nhanh chóng đạt tới 0 cho các chuỗi có chiều dài chỉ từ 10 đến 20.
Để biết cách xử lý sâu hơn các mạng hồi quy như các hệ thống động, tham khảo Doya (1993), Bengio et al. (1994) và Siegelmann and Sontag (1995), với hướng dẫn trong Pascanu et al. (2013). Các phần còn lại của chương sẽ thảo luận về các phương pháp đã được đề xuất đẻ giảm thiểu khó khăn trong việc học các phụ thuộc xa (trong một số trường hợp cho phép RNN học các phụ thuộc hàng trăm bước), nhưng vấn đề của phụ thuộc xa vẫn còn là một trong những thử thách chính trong học sâu.10.8. Hải
10.8. Echo state networks.
Echo state network (ESN) cung cấp kiến trúc và nguyên tắc học có giám sát cho mạng nơ ron hồi quy (RNNs). Ý tưởng chính là (i) điều khiển một mạng nơ ron tái phát ngẫu nhiên, lớn, cố định với tín hiệu đầu vào, từ đó tạo ra trong mỗi nơron trong mạng "reservoir" này một tín hiệu phản hồi phi tuyến và (ii) kết hợp tín hiệu đầu ra mong muốn bằng một kết hợp tuyến tính có thể huấn luyện của tất cả các tín hiệu đáp ứng.
Phương pháp ESN
	Bước 1: Cung cấp RNN ngẫu nhiên. (i) Tạo một reservoir RNN ngẫu nhiên, sử dụng bất kỳ mô hình nơ ron nào. Kích thước reservoir N là phụ thuộc vào nhiệm vụ. Trong tác vụ demo, N = 200 đã được dùng. (ii) Gắn các đơn vị đầu vào vào hồ chứa bằng cách tạo các kết nối tất cả ngẫu nhiên. (iii) Tạo các đơn vị đầu ra. Nếu tác vụ yêu cầu phản hồi đầu ra (tác vụ tạo tần số thực hiện), hãy cài đặt các kết nối output-to-reservoir được tạo ngẫu nhiên (all-to-all). Nếu tác vụ không yêu cầu phản hồi đầu ra, không tạo bất kỳ kết nối nào đến/đi từ các đơn vị đầu ra trong bước này.
	Bước 2: Thu hoạch trạng thái hồ chứa. Điều khiển dynamical reservoir với dữ liệu đào tạo D với n = 1, ..., nmax. Trong ví dụ demo, nơi có các kết nối phản hồi đầu ra đến reservoir, điều này có nghĩa là ghi cả hai đầu vào u(n) vào đơn vị đầu vào và đầu ra của y(n) vào đơn vị đầu ra. Trong các tác vụ không có phản hồi đầu ra, reservoir được điều khiển bởi đầu vào u(n). Điều này dẫn đến một chuỗi x(n) của N-dimensional reservoir state. Mỗi tín hiệu thành phần x(n) là một biến đổi phi tuyến của đầu vào. Trong bản demo, mỗi x(n) là một tổ hợp riêng lẻ của cả tín hiệu đầu vào bước chậm và hình sin đầu ra nhanh (Hình 1).
	Bước 3: Tính trọng lượng đầu ra. Tính trọng số đầu ra là trọng số hồi quy tuyến tính của đầu ra y(n) trên các x(n). Sử dụng các trọng số này để tạo các kết nối giữa reservoir với đầu ra (mũi tên chấm trong Hình 1). Việc đào tạo đã hoàn tất và ESN đã sẵn sàng để sử dụng. Hình 2 cho thấy tín hiệu đầu ra thu được khi ESN được đào tạo với đầu vào bước chậm được hiển thị trong cùng một hình.
 
(Hình 1) Mũi tên nét liền chỉ các kết nối cố định ngẫu nhiên, mũi tên nét đứt chỉ các kết nối
 
(Hình 2) Sóng màu đen là đầu ra chuẩn, sóng hình sin màu xám là đầu ra mạng.
The recurrent weights ánh xạ từ h(t-1) tới h(t) và the input weights ánh xạ từ x(t) tới h(t) là một trong những điều khó nhất trong việc học the recurrent networks. Một ý kiến đưa ra nhằm tránh khỏi khó khăn trên bằng cách thiết lập the recurrent weights sao cho các hidden units có thể ghi nhớ được những gì đã học và chỉ học the output weights. Một ý tưởng khác nói về echo state networks và liquid state machines bằng cách sự dụng spiking nơ rơn thày vì các hidden units mà có giá trị liên tục dùng cho ESNs. Chúng được gọi là Reservoir computing.
Có một cách hiểu về Reservoir computing recurrent networks là coi chúng như phần lõi máy: chúng ánh xạ một véc tơ có độ dài tùy ý vào một véc tơ có độ dài ổn định mà tại đó có thể giải quyết vấn đề. The training criterion(tiêu chí) có thể đưa ra các chức năng của the input weights.
Ý tưởng ban đầu là làm cho giá trị riêng của Jacobians tiến dần tới 1. Như đã trình bày trong 8.2.5, phần trọng trọng về the recurrent weights là phổ giá trị riêng của Jacobians là  . Cần chú ý là Spectral radius của J sẽ xác định giá trị cực đại của nó.
Để hiểu tác dụng của spectral radius, xét trường hợp đơn giản của sự lan truyền ngược với ma trận J mà không thay đổi t. Với trường hợp này, khi mạng hoàn toàn tuyến tính, giả sử J có véc tơ riêng v tương ứng với giá trị riêng λ. Xét những gì xảy ra khi ta cho một vector gradient đi ngược lại t. nếu chúng ta bắt dầu với một vector gradient G, sau đó sau 1 bước lan truyền ngược, chúng ta sẽ có JG, và sau n bước ta có J(n)G. Từ đây chúng ta có thể thấy rằng lan truyền ngược bắt đầu từ g và truyền ngược bắt đầu từ g + δv phân ra bởi δJ(n)v sau khi bước n của lan truyền ngược. Vậy nếu bây giờ ta bắt đầu với G + δv, sau đó một bước, chúng ta có J(G+δv), và sau n bước ta có J n (G+δv). Nếu v được chọn chọn để trở thành một giá trị riêng đơn vị J với λ riêng. Hai bước lan truyền ngược bị chia cắt bởi khoảng cách δ|λ|n với v tương ứng với giá trị lớn nhất của | λ |. Khi | λ | > 1, độ lệch δ|λ|n tang theo cấp số nhân. Khi | λ | <1, độ lệch sẽ bé đi theo cấp số nhân. Tất nhiên, ví dụ này giả định rằng Jacobian là như nhau ở mọi bước thời gian.
Tất cả những gì chúng ta đã nói về việc truyền lại thông qua các ma trận lặp đi lặp lại đều áp dụng cho việc truyền thông tương đương trong một mạng lưới mà không phi tuyến h(t+1) = h(t)T W.
Biến đổi tuyến tính W(T) luôn luôn co lại h được đo bằng L2 khi đó nói biểu đồ là co lại(contractive). Khi spectral radius ít hơn 1 thì ánh xạ từ h(t) đến h(t+1) cũng contractive. Do đó mỗi sự thay đổi trở lên nhỏ hơn sau mỗi bước
Ma trận Jacobian cho biết làm thế nào một sự thay đồi nhỏ của h(t) truyền một bước về phía trước, làm thế nào gradient h(t+1) truyền lùi một bước trong lan truyền ngược.
Với một bản đồ phi tuyến, Jacobian được coi là miễn thay đổi tại mỗi bước. Tuy nhiên, nó vẫn đúng khi sự thay đổi nhỏ có thể biến thành sự thay đổi lớn sau vài bước.	
Chiến lược của echo state networks là đơn giản chỉ để thay đổi weight để có một số spectral radius như là 3, nơi thông tin được chuyển qua thời gian nhưng không bùng nổ(explode) vì tác dụng ổn định của phi tuyến tính bão hòa như tanh.
10.9. Leaky units and other strategies for multiple time scales.
Một cách để đối phó với sự phụ thuộc lâu dài là thiết kế một mô hình hoạt động ở nhiều quy mô thời gian, do đó một số bộ phận của mô hình hoạt động với thời gian liên tục và có thể xử lý các chi tiết nhỏ, trong khi các bộ phận khác hoạt động với thời gian rời rạc và chuyển thông tin từ quá khứ xa xôi đến nay hiệu quả hơn. Các chiến lược khác nhau để xây dựng quy mô thời gian rời rạc có thể xảy ra. Chúng bao gồm việc bổ sung các kết nối bỏ qua thời gian, “leaky units” được tích hợp tín hiệu với hằng số thời gian khác, và việc loại bỏ một số các kết nối sử dụng để mô hình hóa quy mô thời gian liên tục.
10.9.1. Adding Skip Connections through Time
Một cách để có được mô hình thời gian rời rạc là thêm các kết nối trực tiếp từ biến trong quá khứ tới biến trong hiện tại. Trong một recurrent networks, một recurrent connection đi từ một đơn vị thời gian t tới một đơn vị thời gian t+1. 
Như đã biết trong 8.2.5, gradient có thể vanish (tan biến) hoặc explosion theo cấp số nhân đối với số bước thời gian. Gradient bây giờ giảm theo cấp số nhân theo hàm τ/d theo vì là τ.
10.9.2. Leaky units and a spectrum of different time scales.
Khi chúng ta tích lũy một μ(t) trung bình với một giá trị v(t) bằng cách: µ(t) ←αµ (t-1) + (1−α)v(t) với tham số α là một ví dụ về một tuyến tính tự liên kết từ μ(t-1) tới μ(t). khi α càng gần 1, trung bình vận hành ghi nhớ thông tin về quá khứ càng lâu. Và khi α càng gần 0, thông tin về quá khứ nhanh chóng bị loại bỏ. Đon vị ẩn với tuyến tính tự liên kết có thể xử lý tương tự như vậy gọi là Leaky units.
Bỏ qua kết nối sau d bước thời gian là cách để đảm bảo một đơn vị có thể học được cách tạo một giá trị sau d bước trước đó. Phương pháp tự liên kết tuyến tính hoạt động trơn tru và linh hoạt hơn bằng cách điều chỉnh giá trị thực α.
10.9.3. Removing connections.
Đây là ý tưởng khác từ (the skip connection) kết nối rời rạc đã thảo luận trước đó vì nó liên quan mật thiết đến việc loại bỏ kết nối độ dài đơn lẻ và thay thế chúng bằng các kết nối dài hơn. Đơn vị nhận kết nối mới có thể học cách hoạt động trên quy mô thời gian dài nhưng cũng có thể chỉ tập trung vào các kết nối ngắn hạn.
10.10. The long short-term memory and other gated RNNs.
Hầu hết các mô hình hiệu quả sử dụng trong các ứng dụng thực tế gọi là RNNs gated. Chúng bao gồm the long short-term memory và gated recurrent units.
Giống như Leaky units, RNNs gated được dựa trên ý tưởng tạo ra đường dẫn qua thời gian mà không bị vanish hay explode. Cổng RNNs khái quát giúp cho connection weight thay đổi theo thời gian.
Đây là sơ đồ khối của LSTM recurrent network “cell”. Cells thay thế các hidden units của recurrent networks bình thường. The state unit có tuyến tính self-loop mà weight được kiểm soát bởi the forget gate. Đầu ra của cell có thể bị ngắt bới output gate. Tất cả các gating units đều có một phi tuyến tính xích ma, trong khi các input unit có thể có phi tuyến tính đáp lại. các state unit có thể dùng như là đầu vào cho gating units. Hình vuông màu đen thê hiện sự chậm trễ trong một bước thời gian.
 
					Sơ đồ 10.16.
10.10.1. Long short-term memory.
Sơ đồ khối LSTM được minh họa trong hình 10.16. LSTM recurrent networks có “LTSM cell”, có thể tự tái phát ngoài việc tự tái phát bên ngoài RNN. Quan trọng nhất là state unit s(t) có tuyến tính giống Leaky units.
 
 
 
 
Với x(t) là đầu vào hiện tại, h(t) là hidden layer vector hiện tại, bf, Uf, Wf là espectively biases, input weights và recurrent weights for the forget gates, g(t) là external input gate unit, q(t) là output gate, s(t) là extra input.
10.10.2. Other gated RNNs
Khác biệt chủ yếu so với LSTM là một gating unit cùng lúc kiểm soát yếu tố quên và quyết định cập nhật the state unit. Công thức cập nhật như sau
 
Với u đại diện cho cổng" updated" và r đại diện cho cổng"reset". Giá trị của chúng được định nghĩa 
 
Reset và update gates có thể đơn phương “bỏ qua” các phần của state vector.
The update gates hoạt động giống như leaky integrators có thể chuyển động tuyến tính theo bất cứ chiều nào, do đó có thể chọn sao chép hoặc bỏ mặc nó bằng cách thay thế nó với “target state”. 



10.11. Optimization for Long-Term Dependencies (Tối ưu hoá cho các phụ thuộc dài hạn)
Mục 8.2.5 và phần 10.7 đã mô tả các vấn đề về sự biến mất và bùng nổ xảy ra khi tối ưu hóa RNNs qua nhiều bước thời gian.
Một ý tưởng thú vị được đề xuất bởi Martens và Sutskever (2011) là các đạo hàm bậc hai có thể biến mất cùng một lúc mà các đạo hàm bậc một biến mất. Thuật toán tối ưu hóa thứ hai có thể được hiểu là phân chia đạo hàm bậc nhất bời đạo hàm bậc hai (trong chiều cao hơn, nhân gradient bằng phép nghịch đảo Hessian). Nếu đạo hàm bậc hai co lại ở một tỷ lệ tương tự với đạo hàm bậc nhất, thì tỷ số của các đạo hàm bậc nhất và bậc hai có thể vẫn tương đối giữ nguyên. Thật không may, phương pháp thứ hai có nhiều hạn chế, bao gồm cả chi phí tính toán cao, sự cần thiết cho một minibatch lớn, và một xu hướng được thu hút vào các điểm yên. Martens and Sutskever (2011) đã tìm thấy kết quả đầy hứa hẹn bằng cách sử dụng các phương pháp bậc hai. Sau đó, Sutskever et al. (2013) thấy rằng các phương pháp đơn giản hơn như động lượng Nesterov với khởi tạo cẩn thận có thể đạt được kết quả tương tự. Xem Sutskever (2012) để biết thêm chi tiết. Cả hai cách tiếp cận này phần lớn đã được thay thế bằng cách sử dụng SGD (thậm chí không có động lượng) áp dụng cho LSTM. Đây là một phần của một chủ đề tiếp tục trong học máy: thiết kế một mô hình dễ tối ưu dễ hơn là thiết kế một thuật toán tối ưu mạnh mẽ
10.11.1. Clipping Gradients
Như đã thảo luận trong phần 8.2.4, các hàm phi tuyến mạnh mẽ như được tính toán bằng recurrent network qua nhiều bước có xu hướng có các đạo hàm có thể có độ lớn rất lớn hoặc rất nhỏ. Điều này được minh họa trong hình 8.3 và hình 10.17, trong đó chúng ta thấy rằng hàm mục tiêu (như là một hàm của các tham số) có một "cảnh quan" trong đó ta thấy "vách đá": các vùng rộng và bằng phẳng cách nhau bởi các vùng nhỏ nơi chức năng khách quan thay đổi nhanh chóng, tạo thành một loại vách đá.
Khó khăn phát sinh là khi tham số gradient rất lớn, bản cập nhật tham số gradient có thể ném các tham số rất xa, vào một khu vực nơi hàm mục tiêu lớn hơn, hoàn tác phần lớn công việc đã được thực hiện để đạt được giải pháp hiện tại. Gradient cho chúng ta biết hướng tương ứng với gốc dốc nhất trong một vùng cực nhỏ xung quanh các tham số hiện tại. Bên ngoài vùng cực tiểu này, hàm chi phí có thể bắt đầu cong lên trên. Bản cập nhật phải được chọn là đủ nhỏ để tránh đi qua độ cong lên quá nhiều. Chúng tôi thường sử dụng tỷ lệ học tập phân rã từ từ đủ để các bước liên tiếp có cùng tốc độ học tập. Một kích thước bước thích hợp cho một phần tương đối tuyến tính của cảnh quan thường không phù hợp và gây ra chuyển động khó khăn nếu chúng ta nhập một phần cong hơn của cảnh quan vào bước tiếp theo.
 
Hình 10.17: Ví dụ về hiệu ứng của việc cắt gradient trong một recurrent network với hai tham số w và b. Gradient cắt có thể làm cho gradient descent thực hiện hợp lý hơn trong vùng lân cận của những cliffs dốc đứng. Những cliffs dốc đứng này thường xảy ra trong các recurrent network gần nơi một recurrent network hoạt động gần như tuyến tính. Cliffs dốc đứng theo cấp số nhân trong số bước thời gian vì ma trận trọng số được nhân lên một lần cho mỗi bước thời gian. (Trái) Gradient descent mà không có gradient clipping vượt qua đáy của khe núi nhỏ này, sau đó nhận được một gradient rất lớn từ mặt cliffs. Các gradient lớn thảm họa đẩy các tham số bên ngoài các trục của đồ thị. (Phải) Gradient descent với gradient clipping có một phản ứng trung bình hơn với cliffs. Trong khi nó leo lên mặt vách đá, kích thước bước bị giới hạn để nó không thể được đẩy ra khỏi vùng dốc gần giải pháp. Hình được điều chỉnh với sự cho phép của Pascanu et al. (2013).
Một loại giải pháp đơn giản đã được sử dụng bởi các học viên trong nhiều năm: cắt bớt gradient. Có những trường hợp khác nhau của ý tưởng này (Mikolov, 2012; Pascanu và cộng sự, 2013). Một tùy chọn là để cắt gradient tham số từ một minibatch element-wise (Mikolov, 2012) ngay trước khi cập nhật tham số. Một tuỳ chọn khác là để cắt norm || g || của gradient g (Pascanu et al., 2013) ngay trước khi cập nhật thông số
  
trong đó v là ngưỡng chuẩn và g được sử dụng để cập nhật các tham số. Vì gradient của tất cả các tham số (bao gồm các nhóm tham số khác nhau, chẳng hạn như trọng số và độ lệch) được tái chuẩn hóa chung với một hệ số tỷ lệ đơn lẻ, phương pháp thứ hai có lợi thế là nó đảm bảo rằng mỗi bước vẫn theo hướng gradient, nhưng thử nghiệm gợi ý rằng cả hai biểu mẫu đều hoạt động tương tự nhau. Mặc dù cập nhật tham số có cùng hướng với gradient thực, với phép cắt gradient norm, tham số vectơ cập nhật tham số hiện bị chặn. Gradient bị chặn này tránh thực hiện một bước bất lợi khi gradient bùng nổ. Trong thực tế, thậm chí chỉ đơn giản là tham gia một bước ngẫu nhiên khi gradient cường độ là trên ngưỡng có xu hướng làm việc gần như là tốt. Nếu vụ nổ quá nghiêm trọng đến độ dốc là Inf hoặc Nan (được coi là vô hạn hoặc không phải là một số), thì một bước ngẫu nhiên của size v có thể được thực hiện và thường sẽ di chuyển ra khỏi cấu hình số không ổn định. Việc cắt bớt chỉ tiêu gradient cho mỗi minibatch sẽ không thay đổi hướng của gradient cho một minibatch riêng lẻ. Tuy nhiên, lấy mức trung bình của gradient cắt theo chuẩn từ nhiều minibatches không tương đương với việc cắt chuẩn của gradient thực (gradient được hình thành từ việc sử dụng tất cả các ví dụ). Ví dụ có định mức gradient lớn, cũng như các ví dụ xuất hiện trong cùng một minibatch như các ví dụ như vậy, sẽ có đóng góp của họ theo hướng cuối cùng giảm đi. Điều này tương phản với độ dốc truyền thống của minibatch, nơi mà hướng gradient thực sự bằng với mức trung bình trên tất cả các gradient của minibatch. Nói cách khác, gốc stochastic gradient descent truyền thống sử dụng ước tính không thiên vị của gradient, trong khi gradient descent với clipping chuẩn giới thiệu một xu hướng heuristic mà chúng ta biết theo kinh nghiệm là hữu ích. Với việc cắt bớt phần tử, hướng của bản cập nhật không được căn chỉnh với độ dốc thực hoặc độ dốc nhỏ, nhưng nó vẫn là hướng gốc. Nó cũng đã được đề xuất (Graves, 2013) để cắt gradient được truyền lại (đối với các đơn vị ẩn) nhưng không có sự so sánh nào được công bố giữa các biến thể này; chúng tôi phỏng đoán rằng tất cả các phương pháp này hoạt động tương tự.
 
10.11.2. Regularizing to Encourage Information Flow (Thường xuyên để khuyến khích luồng thông tin)
Gradient clipping giúp giải quyết các gradient đang bùng nổ, nhưng nó không hỗ trợ biến mất gradient. Để giải quyết vấn đề biến mất dần dần và chụp tốt hơn phụ thuộc, chúng tôi đã thảo luận ý tưởng tạo đường dẫn trong biểu đồ tính toán của kiến trúc lặp lại mở ra mà theo đó sản phẩm của các gradient được liên kết với vòng cung là gần 1. Một cách tiếp cận để đạt được điều này là với LSTM và các cơ chế tự vòng và gating khác, được mô tả ở trên trong phần 10.10. Một ý tưởng khác là để thường xuyên hóa hoặc hạn chế các tham số để khuyến khích "luồng thông tin". Đặc biệt, chúng ta muốn vector gradient ∇(t) L được truyền lại để duy trì độ lớn của nó, ngay cả khi hàm mất mát chỉ penalizes đầu ra ở cuối chuỗi. Chính thức, chúng tôi muốn 
 
lớn bằng
  
Với mục tiêu này, Pascanu et al. (2013) đề xuất trình như chỉnh sửa sau:
 
Tính toán gradien của trình chỉnh sửa này có thể xuất hiện khó khăn, nhưng Pascanu et al. (2013) đề xuất một xấp xỉ trong đó chúng tôi xem xét việc truyền bá ngược vectơ ∇ (t) L như thể chúng là các hằng số (cho mục đích của trình chuẩn hóa này, vì vậy h rằng không cần phải truyền lại thông qua chúng). Các thí nghiệm với trình thông thường này gợi ý rằng, nếu kết hợp với tiêu chuẩn cắt heuristic (xử lý vụ nổ gradient), trình thông thường có thể tăng đáng kể khoảng thời gian phụ thuộc mà RNN có thể học. Bởi vì nó giữ các động lực RNN trên các cạnh của gradient bùng nổ, gradient clipping là đặc biệt quan trọng. Nếu không có gradient clipping, gradient bùng nổ ngăn cản việc học từ thành công. Điểm yếu chính của phương pháp này là nó không hiệu quả như LSTM cho các nhiệm vụ mà dữ liệu phong phú, chẳng hạn như mô hình hóa ngôn ngữ.
10.12. Explicit Memory (Bộ nhớ rõ ràng)
Trí thông minh đòi hỏi tri thức và thu nhận tri thức có thể được thực hiện qua việc học, điều này đã thúc đẩy sự phát triển của kiến trúc sâu quy mô lớn. Tuy nhiên, có nhiều loại kiến thức khác nhau. Một số kiến thức có thể tiềm ẩn, ý thức và khó để nói ra lời - chẳng hạn như cách đi bộ hoặc cách một chú chó khác với mèo. Các kiến thức khác có thể rõ ràng, khai báo và tương đối đơn giản để đưa vào các từ — mỗi ngày hiểu biết chung, như “một con mèo là một loại động vật” hoặc các sự kiện rất cụ thể mà bạn cần phải biết để hoàn thành các mục tiêu hiện tại của mình, như “cuộc họp với nhóm bán hàng là lúc 3:00 chiều trong phòng 141”.
Các mạng nơron nổi trội trong việc lưu trữ kiến thức tiềm ẩn. Tuy nhiên, chúng “struggle” để lưu trữ sự kiện. Stochastic gradient descent đòi hỏi nhiều sự trình diễn của cùng một đầu vào trước khi nó có thể được lưu trữ trong một tham số mạng nơ-ron, và thậm chí sau đó, đầu vào đó sẽ không được lưu trữ đặc biệt chính xác. Gravesetal. (2014b) đưa ra giả thuyết rằng điều này là do các mạng nơron thiếu tương đương với hệ thống bộ nhớ làm việc cho phép con người nắm giữ và thao tác một cách rõ ràng các thông tin có liên quan để đạt được một số mục tiêu. Các thành phần explicit memory như vậy sẽ cho phép các hệ thống của chúng tôi không chỉ nhanh chóng và " intentionally" lưu trữ và truy xuất các sự kiện cụ thể mà còn để lý do tuần tự với chúng. Sự cần thiết cho các mạng nơ-ron có thể xử lý thông tin theo trình tự các bước, thay đổi cách thức đầu vào được đưa vào mạng ở từng bước, từ lâu đã được công nhận là quan trọng đối với khả năng lý luận hơn là thực hiện các phản hồi trực quan, tự động đầu vào (Hinton, 1990).
  
Hình 10.18: Một sơ đồ về một ví dụ về mạng có eplicit memory, chụp một số thành phần thiết kế chính của máy Turing thần kinh. Trong sơ đồ này, chúng ta phân biệt phần “representation” của mô hình (“mạng nhiệm vụ”, ở đây một recurrent net ở phía dưới) từ phần “memory” của mô hình (tập hợp ô), có thể lưu trữ các sự kiện. Task networks học cách “control” bộ nhớ, quyết định nơi đọc và nơi ghi trong bộ nhớ (thông qua các cơ chế đọc và ghi, được chỉ báo bằng các mũi tên đậm trỏ vào địa chỉ đọc và ghi)
Để giải quyết khó khăn này, Weston et al. (2014) đã giới thiệu các mạng bộ nhớ bao gồm một bộ các tế bào bộ nhớ có thể được truy cập thông qua cơ chế giải quyết địa chỉ. Mạng bộ nhớ ban đầu yêu cầu một tín hiệu giám sát hướng dẫn họ cách sử dụng các tế bào bộ nhớ của họ. Graves et al. (2014b) đã giới thiệu máy Turing thần kinh, có khả năng học đọc và viết nội dung tùy ý vào các tế bào bộ nhớ mà không cần giám sát rõ ràng về hành động nào thực hiện và cho phép đào tạo từ đầu đến cuối mà không có tín hiệu giám sát này, thông qua việc sử dụng một cơ chế chú ý mềm dựa trên nội dung (xem Bahdanau và cộng sự (2015) và phần 12.4.5.1). Cơ chế giải quyết mềm này đã trở thành tiêu chuẩn với các kiến trúc có liên quan khác mô phỏng các cơ chế thuật toán theo cách vẫn cho phép tối ưu hóa dựa trên gradient (Sukhbaatar và cộng sự, 2015; Joulin và Mikolov, 2015; Kumar và cộng sự, 2015; Vinyals et al., 2015a; Grefenstette và cộng sự, 2015).
Mỗi tế bào bộ nhớ có thể được coi là một phần mở rộng của các tế bào bộ nhớ trong LSTMs và GRUs. Sự khác biệt là mạng đầu ra một trạng thái bên trong chọn các ô để đọc hoặc ghi vào, giống như truy cập bộ nhớ trong một máy tính kỹ thuật số đọc từ hoặc ghi vào một địa chỉ cụ thể.
Rất khó để tối ưu hóa các hàm tạo ra các địa chỉ chính xác, số nguyên. Để giảm bớt vấn đề này, NTMs thực sự đọc hoặc ghi từ nhiều tế bào bộ nhớ cùng một lúc. Để đọc, họ lấy trọng số trung bình của nhiều ô. Để viết, họ sửa đổi nhiều ô bằng các số lượng khác nhau. Các hệ số cho các hoạt động này được chọn để tập trung vào một số lượng nhỏ các tế bào, ví dụ, bằng cách sản xuất chúng thông qua một hàm softmax. Sử dụng các trọng số này với các dẫn xuất khác không cho phép các chức năng kiểm soát truy cập vào bộ nhớ được tối ưu hóa bằng cách sử gradient descent. Gradient trên các hệ số này cho biết liệu mỗi hệ số có được tăng hay giảm, nhưng gradient thường sẽ chỉ lớn đối với những địa chỉ bộ nhớ nhận được một hệ số lớn.
Các ô nhớ này thường được tăng cường để chứa một véc tơ, chứ không phải là một vô hướng duy nhất được lưu trữ bởi một ô nhớ LSTM hoặc GRU. Có hai lý do để tăng kích thước của ô nhớ. Một lý do là chúng tôi đã tăng chi phí truy cập vào một tế bào bộ nhớ. Chúng tôi trả chi phí tính toán của việc tạo ra một hệ số cho nhiều ô, nhưng chúng tôi mong đợi các hệ số này sẽ tập trung xung quanh một số lượng nhỏ các ô. Bằng cách đọc giá trị vector, thay vì giá trị vô hướng, chúng tôi có thể bù đắp một số chi phí này. Một lý do khác để sử dụng các ô nhớ có giá trị vector là chúng cho phép địa chỉ dựa trên nội dung, trong đó trọng số được sử dụng để đọc hoặc viết từ một ô là một hàm của ô đó. Các ô có giá trị vector cho phép chúng ta lấy ra một bộ nhớ có giá trị vector đầy đủ nếu chúng ta có thể tạo ra một mẫu phù hợp với một số nhưng không phải tất cả các phần tử của nó. Điều này tương tự như cách mà mọi người có thể nhớ lại lời bài hát của một bài hát dựa trên một vài từ. Chúng ta có thể nghĩ về một hướng dẫn đọc dựa trên nội dung nói rằng, "Lấy lời của bài hát có điệp khúc" Tất cả chúng ta đều sống trong một tàu ngầm màu vàng. '"Địa chỉ dựa trên địa chỉ là hữu ích hơn khi chúng ta làm cho các đối tượng được lấy ra lớn - nếu mỗi bức thư của bài hát được lưu trữ trong một ô nhớ riêng biệt, chúng tôi sẽ không thể tìm thấy chúng theo cách này. Bằng cách so sánh, địa chỉ dựa trên vị trí không được phép tham chiếu đến nội dung của bộ nhớ. Chúng ta có thể nghĩ về một hướng dẫn đọc dựa trên vị trí như nói "Lấy lời bài hát trong bài hát ở vị trí 347." Địa chỉ dựa trên địa chỉ thường có thể là một cơ chế hoàn toàn hợp lý ngay cả khi các ô nhớ nhỏ.
Nếu nội dung của ô nhớ được sao chép (không bị lãng quên) ở hầu hết các bước thời gian, thì thông tin nó chứa có thể được nhân lên trong thời gian tới và các gradient được truyền ngược thời gian mà không bị biến mất hoặc bùng nổ.
Cách tiếp cận explicit memory được minh họa trong hình 10.18, nơi chúng ta thấy rằng một " task neural network" được kết hợp với một bộ nhớ. Mặc dù task neural network có thể là feedforward hoặc recurrent, hệ thống tổng thể là một recurrent network. Task network có thể chọn đọc hoặc ghi vào các địa chỉ bộ nhớ cụ thể. Explicit memory dường như cho phép các mô hình học các nhiệm vụ mà RNNs hoặc LSTM RNNs bình thường không thể học được. Một lý do cho lợi thế này có thể là do thông tin và gradient có thể được lan truyền (chuyển tiếp theo thời gian hoặc ngược thời gian, tương ứng) trong khoảng thời gian rất dài.
Để thay thế cho việc truyền lại thông qua các trung bình có trọng số của các ô nhớ, chúng ta có thể giải thích các hệ số địa chỉ bộ nhớ như xác suất và chỉ đọc một cách đơn giản (Zaremba và Sutskever, 2015). Tối ưu hóa các mô hình đưa ra quyết định rời rạc đòi hỏi thuật toán tối ưu hóa chuyên ngành, được mô tả trong phần 20.9.1. Cho đến nay, đào tạo những kiến trúc ngẫu nhiên mà đưa ra quyết định rời rạc vẫn khó hơn các thuật toán xác định đào tạo đưa ra quyết định mềm.
Cho dù nó soft (cho phép truyền lại) hay stochastic và khó, cơ chế chọn địa chỉ ở dạng giống hệt với attention mechanism đã được giới thiệu trước đây trong ngữ cảnh dịch máy (Bahdanau et al., 2015) và thảo luận trong phần 12.4.5.1. Ý tưởng về các attention mechanism cho các mạng thần kinh được giới thiệu thậm chí sớm hơn, trong bối cảnh tạo chữ viết tay (Graves, 2013), với một attention mechanism bị hạn chế chỉ di chuyển về phía trước theo thời gian. Trong trường hợp dịch máy và memory networks, ở mỗi bước, trọng tâm của sự chú ý có thể di chuyển đến một nơi hoàn toàn khác, so với bước trước đó.
Recurrent neural networks cung cấp một cách để mở rộng việc học sâu vào dữ liệu tuần tự. Chúng là công cụ chính cuối cùng trong hộp công cụ học tập sâu của chúng ta. Cuộc thảo luận của chúng tôi bây giờ chuyển sang cách chọn và sử dụng những công cụ này và cách áp dụng chúng vào các tác vụ trong thế giới thực.

Phần 3 - Chapter 2:
Word Vector Representations
Khi trao đổi giữa các ngôn ngữ và từ ngữ, chúng ta có thể sẽ phân loại văn bản trên hàng ngàn lớp học, mục đích để sử dụng trong tác vụ xử lí ngôn ngữ tự nhiên (NLP). Nhiều nghiên cứu đã được thực hiện trong lĩnh vực này trong những năm gần đây, và điều này đã dẫn đến việc chuyển đổi của các từ trong ngôn ngữ sang định dạng vectơ, vì như thế nó có thể được sử dụng trong nhiều bộ thuật toán và quy trình. Chương này cung cấp giải thích chi tiết về phép nhúng từ và hiệu quả của chúng. Chúng tôi giới thiệu nguồn gốc của nó và so sánh các mô hình khác nhau được sử dụng để thực hiện các tác vụ NLP khác nhau.
2.1. Introduction to Word Embedding
Việc phân loại và hạn định các từ có ngữ nghĩa tương đồng nhau đi kèm theo phiếu tự đánh giá ngữ nghĩa dựa trên cách phân chia của họ trong việc sử dụng ngôn ngữ. Không gian vectơ mô hình, biểu thị các tài liệu văn bản và truy vấn dưới dạng vectơ, có từ lâu đời và đã được sử dụng cho mục đích phân phối ngữ nghĩa. Việc biểu diễn các từ qua mô hình không gian vectơ trong không gian vectơ N-chiều là hữu ích cho các thuật toán NLP khác nhau để đạt được kết quả tốt hơn, vì nó dẫn đến các nhóm văn bản tương tự trong không gian vectơ mới.
Thuật ngữ nhúng từ được đặt ra bởi Yoshua Bengio trong giấy “A Neural Probabilistic Language Model” (Mô hình ngôn ngữ xác suất thần kinh) (www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf). Tiếp theo là Ronan Collobert và Jason Weston trong bài báo “A Unified Architecture for Natural Language Processing” (kiến trúc thống nhất cho Xử lý ngôn ngữ tự nhiên) (https://ronan.collobert.com/pub/matos/2008_nlp_icml.pdf), trong đó các tác giả đã chứng minh cách sử dụng học đa nhiệm và học bán giám sát cải thiện việc khái quát hóa các nhiệm vụ được chia sẻ. Cuối cùng, Tomas Mikolov và cộng sự, người đã tạo ra word2vec và đặt các từ nhúng dưới ống kính, làm sáng tỏ việc training cho các từ nhúng và sử dụng các từ nhúng sẵn có. Sau đó, Jeffrey Pennington đã giới thiệu GloVe, một tập hợp các từ nhúng khác.
Các mô hình nhúng từ đã được chứng minh là hiệu quả hơn các mô hình bag-of-word hoặc one-hot-encoding, được tạo thành từ các vectơ thưa thớt có kích thước tương đương với từ vựng, được sử dụng ban đầu. Sự thưa thớt trong biểu diễn véc tơ là kết quả của phong phú từ vựng và ghi nhãn của từ hoặc tài liệu trong nó ở vị trí chỉ mục. Word embedding đã thay thế tư tưởng này bằng cách sử dụng các từ xung quanh của tất cả các từ đơn lẻ, bằng cách sử dụng thông tin hiện tại từ văn bản đã cho và truyền nó cho mô hình. Điều này đã cho phép nhúng có dạng một vectơ dày đặc, trong một không gian vectơ liên tục, đại diện cho phép chiếu của các từ riêng lẻ. Nhúng do đó đề cập đến các tọa độ của từ trong không gian vectơ mới học. 
Ví dụ sau đây trình bày việc tạo một vectơ từ, sử dụng one-hot encoding cho các từ có trong tập mẫu, tiếp theo cải thiện các vectơ từ. Nó sử dụng một cách gián tiếp và cho thấy cách thành phần vector cuối cùng có thể được sử dụng để suy ra mối quan hệ giữa các từ.
	Giả sử từ vựng của chúng tôi chứa các từ, Rome, Italy, Paris, France và country. Chúng ta có thể sử dụng từng từ để tạo ra một biểu diễn, sử dụng một sơ đồ one-hot cho tất cả các từ, như được minh họa cho Rome trong Hình 2-1
 
Hình 2-1. Đại diện của Rome
Bằng cách tiếp cận trước khi trình bày các từ dưới dạng véc-tơ, chúng ta có thể sử dụng nhiều hay ít để kiểm tra sự bình đẳng giữa các từ, bằng cách so sánh các vectơ. Cách tiếp cận này không phục vụ các mục đích khác, hoặc mục đích cao hơn. Trong một hình thức biểu diễn tốt hơn, chúng ta có thể tạo nhiều phân cấp hoặc phân đoạn, trong đó thông tin được hiển thị bởi mỗi từ có thể được gán các trọng số khác nhau. Việc lựa chọn các phân đoạn hoặc kích thước này có thể là lựa chọn cá nhân của chúng tôi, và mỗi từ sẽ được thể hiện bằng phân bố trọng số trên các phân đoạn này. Vì vậy, bây giờ chúng ta có một định dạng mới của biểu diễn từ, sử dụng các thang đo khác nhau cho mỗi từ (Hình 2-2).
 
Hình 2.2
Các vectơ được đại diện cho mỗi từ không biểu thị ý nghĩa thực sự của từ đó mà nó cung cấp một thang đo tốt hơn để so sánh giữa các từ. Các vectơ mới được hình thành đủ khả năng trả lời các loại mối quan hệ được giữa các từ. Hình 2-3 đại diện cho các vectơ được hình thành bằng cách sử dụng phương pháp mới này.
 
Hình 2-3
Các vectơ đầu ra của các từ khác nhau vẫn giữ lại các quy tắc và các mẫu của ngôn ngữ, và điều này được chứng minh bằng các bản chuyển đổi tuyến tính của các mẫu này. Ví dụ, kết quả của sự khác biệt giữa các vector và các từ sau, vector (Pháp) - vector (Paris) + vector (Ý), sẽ gần với vector (Rome), như trong Hình 2-4.
 
Hình 2-4
Theo thời gian, Word embeddings đã nổi lên và trở thành một trong những ứng dụng quan trọng nhất của học tập không giám sát. Các mối quan hệ ngữ nghĩa được cung cấp bởi các vectơ từ đã giúp ích cho phương pháp NLP của dịch máy thần kinh, truy xuất thông tin và hỏi-đáp.
Neural Language Model (mô hình ngôn ngữ dây thần kinh) 
Feedforward neural language model (FNNLM) được Bengio đề xuất giới thiệu một mạng nơron đơn thuần gồm một lớp ẩn duy nhất dự đoán các từ tương lai, trong ví dụ của chúng ta, chỉ một từ duy nhất trong chuỗi. 
FNNLM được huấn luyện để tìm θ, giúp tối đa hóa khả năng training tập lục hàm log-likelihood 
 
Ở đây, f là hàm tổng hợp được tạo thành từ các tham số liên quan đến các vectơ đặc trưng phân bố của mỗi từ có trong danh sách từ vựng và các tham số của feedforward hoặc RNN. R(θ) dùng để chỉ cụm từ chuẩn hóa, áp dụng một hình phạt phân rã trọng lượng cho trọng số của mạng thần kinh và ma trận vectơ đặc trưng. Hàm f trả về điểm xác suất được tính bằng công thức softmax cho từ tại vị trí t, sử dụng trước đó n từ.
Các mô hình được giới thiệu bởi Bengio là một trong những mô hình đầu tiên của loại hình này và đặt nền tảng cho các mô hình nhúng từ trong tương lai. Các thành phần của các mô hình này vẫn được sử dụng trên các mô hình nhúng từ hiện tại. Một số thành phần này bao gồm:
1. Embedding layer: thành phần này giữ một bản ghi đại diện của tất cả các từ trong tập dữ liệu tranining. Nó được khởi tạo với một tập hợp các trọng số ngẫu nhiên.
2. Intermediate layer(s): các lớp ẩn, từ lớp đầu đến lớp cuối cùng, số lượng một hoặc nhiều, tạo ra biểu diễn dữ liệu văn bản đầu vào bằng cách áp dụng các hàm phi tuyến trong mạng nơron trên các từ nhúng của các từ n trước đó.
3. Softmax layer: Đây là lớp cuối cùng của kiến trúc mạng nơron và trả về phân bố xác suất trên tất cả các từ có trong input.
Bài báo của Bengio đề cập đến chi phí tính toán, liên quan đến việc chuẩn hóa softmax và nó có một mối quan hệ với kích thước từ vựng. Điều này đã tạo ra những thách thức trong thử nghiệm các thuật toán mới cho các neural language models và các word embedding models từ trên bộ từ vựng đầy đủ.
Neural net language models đã giúp ta khái quát được các từ không có trong từ vựng hiện tại, giống như một chuỗi các từ chưa bao giờ được nhìn thấy trước đây sẽ có xác suất cao hơn nếu có sự kết hợp của các từ đã được bao gồm trong một câu
2.2. Word2vec
Word2vec, hoặc word-to-vector, các mô hình đã được giới thiệu bởi Tomas Mikolov et al. (https://arxiv.org/pdf/1301.3781.pdf) và là một trong những mô hình được sử dụng nhiều nhất. Nó được sử dụng để học word embeddings, hoặc đại diện vector của các từ. Bài báo so sánh hiệu suất của các mô hình được đề xuất với các mô hình trước đó bằng cách kiểm tra sự giống nhau giữa các nhóm từ. Các kỹ thuật được đề xuất trong bài báo dẫn đến việc biểu diễn vectơ giữa các từ có độ tương đồng trên nhiều góc độ khi áp dụng cho các từ tương tự nhau. Sự tương tự của biểu diễn từ vượt quá các quy tắc cú pháp đơn giản, với các phép toán đại số đơn giản cũng có thể được thực hiện trên các vectơ từ.
Các mô hình Word2vec sử dụng nội bộ một mạng nơron đơn giản của một lớp duy nhất và nắm bắt được trọng số của lớp ẩn. Mục đích của việc training mô hình là tìm hiểu trọng số của lớp ẩn, đại diện cho “word embedding”. Mặc dù word2vec sử dụng kiến trúc mạng nơron, bản thân kiến trúc không đủ phức tạp và không sử dụng bất kỳ loại phi tuyến nào thì Nó vẫn có thể được loại bỏ nhãn hiệu của việc học sâu ngay tức khắc.
Word2vec cung cấp một loạt các mô hình được sử dụng để đại diện cho các từ trong một không gian n chiều theo cách như các từ và từ tương tự đại diện cho ý nghĩa gần gũi hơn được đặt gần nhau. Điều này là đúng cho toàn bộ bài tập đặt từ vào chỗ khuyết trong không gian vectơ mới. Chúng tôi sẽ đi qua hai mô hình thường xuyên nhất được sử dụng, skip-gram và continuous bag-of-word (CBOW), tiếp theo triển khai ở TensorFlow (một thư viện phần mềm hỗ trợ machine learning và deep learning). Cả hai mô hình đều tương tự về mặt thuật toán, sự khác biệt chỉ ở cách chúng thực hiện dự đoán. Mô hình CBOW dự đoán các từ trung tâm bằng cách sử dụng ngữ cảnh hoặc các từ xung quanh, và mô hình skip-gram dự đoán các từ ngữ cảnh bằng cách sử dụng các từ trung tâm.
Word2vec giúp giảm kích thước của không gian mã hóa và nén biểu diễn của các từ đến độ dài mong muốn cho vectơ (Hình 2-5). Word2vec tiếp cận từ đại diện trên cơ sở ngữ cảnh. Ví dụ, các từ đồng nghĩa, đối lập, khái niệm tương tự ngữ nghĩa, và các từ tương tự sẽ có mặt trong các ngữ cảnh tương tự trên cùng một văn bản, và do đó, được nhúng theo kiể¬u na ná nhau, và các đoạn nhúng cuối cùng của chúng sẽ nằm gần nhau hơn.
 
Hình 2-5: Sử dụng kích thước cửa sổ để chọn các từ trong câu “Machines can now recognize objects and translate speech in real time” và đào tạo mô hình

2.2.1. Skip-Gram Model
Một mô hình skip-gram sử dụng từ hiện tại trong chuỗi để dự đoán các từ bao quanh. Căn cứ phân loại các từ bao quanh dựa trên quan hệ cú pháp và các lần xuất hiện cùng từ trung tâm. Bất kỳ từ nào xuất hiện trong chuỗi được lấy làm đầu vào cho trình phân loại log-linear, mà nói cách khác nó khiến 1 dự đoán về các từ vào trong một vùng nhất định được xác định trước của các từ xảy ra trước và sau từ trung tâm. Có một sự cân bằng giữa việc lựa chọn vùng các từ và độ phức tạp tính toán và chất lượng của việc dẫn tới các vecto từ. Khi khoảng cách đến các từ liên quan tăng lên, những từ ở xa có liên quan ở mức thấp hơn với từ hiện tại so với các từ ở gần. Điều này được giải quyết bằng cách gán các trọng số như một hàm của khoảng cách từ từ trung tâm và cho trọng số thấp hơn, hoặc lấy mẫu ít hơn cho các từ ở phạm vi cao hơn.
Việc đào tạo mô hình skip-gram không bao hàm phép nhân ma trận dày đặc. Cùng với tối ưu hóa, nó có thể dẫn đến 1 quá trình đào tạo hiệu quả cao cho mô hình.
2.2.2. Model Components: Architecture
Trong ví dụ sau, mạng được sử dụng để đào tạo mô hình, với từ đầu vào được cấp dưới dạng vecto one-hot-encoded (mã hóa 1 lần) và đầu ra là một vecto one-hot-encoded biểu diễn từ đầu ra.
 
	Model Components: Hidden Layer
Việc đào tạo mạng thần kinh được thực hiện bằng cách dùng 1 lớp ẩn, với số lượng nơron tương đương số lượng các thuộc tính hoặc số chiều mà chúng ta muốn biểu diễn từ nhúng.
Trong đồ thị trên chúng tôi đã biểu diễn lớp ẩn với ma trận trọng số có 300 cột, bằng số lượng nơron mà là số lượng các thuộc tính trong vectơ từ nhúng đầu ra cuối, và các hàng là 100,000 bằng kích thước của bộ từ vựng được sử dụng để đào tạo mô hình.
Số lượng nơron được coi là siêu tham số của mô hình và có thể thay đổi theo yêu cầu.
Khi vectơ đầu vào ứng với mỗi từ trong bộ từ vựng là một one-hot-encoded, các tính toán xảy ra trong giai đoạn lớp ẩn (hidden layer) sẽ đảm bảo chỉ có vectơ đúng với từ tương ứng là được chọn từ ma trận trọng số và được truyền vào lớp đầu ra (output layer).
	Như thể hiện trong Hình 2-8, trong trường hợp bộ từ vựng kích thước v, cho bất kỳ từ nào, luôn có “1” tại chỉ số mong muốn trong vectơ đầu vào, và sau khi nhân nó với ma trận trọng số chúng ta nhận được hàng tương ứng với từ làm vectơ đầu ra. Hình 2-8 biểu diễn rõ ràng cách mà ma trận trọng số của lớp ẩn được sử dụng để tính toán bảng tra cứu vector từ.
 
	Ngay cả khi vectơ one-hot-encoded được tạo thành hoàn toàn bởi số 0, nhân một vectơ 1 × 100,000 chiều với 1 ma trận trọng số 100,000 × 300 vẫn sẽ trả về việc lựa chọn hàng tương ứng mà có “1”. Hình 2-9 minh họa cho điều này, và đầu ra của lớp ẩn là vectơ biểu diễn của các từ liên quan.
 

	Model Components: Output Layer
Mục đích chính của việc tính toán từ nhúng là đảm bảo các từ có ý nghĩa tương đồng nằm gần nhau hơn trong không gian vectơ được xác định của chúng ta. Vấn đề này dược tự động xử lý bằng mô hình, bởi vì các từ đồng nghĩa, trong hầu hết các trường hợp được bao quanh bởi các ngữ cảnh tương tự (tức là các từ bao quanh từ đầu vào), mà vốn đã khiến sự điều chỉnh trọng số theo cách tương tự trong quá trình đào tạo (Hình 2-10). Ngoài các từ đồng nghĩa và các từ có nghĩa tương tự, mô hình còn xử lý các trường hợp cản trở vì các từ số nhiều và số ít sẽ có ngữ cảnh tương tự (car and cars).

 
2.2.5. CBOW model
The continuous bag-of-word model cho thấy sự tương đồng cấu trúc với FNNLM như hình 2-11. Trật tự các từ không ảnh hưởng đến the projection layer mà quan trọng là từ đang đưa vào bag để dự đoán đầu ra.
 
Hình 2.11: Mô hình Continuous bag-of-words
The input và the projection layers chia sẻ các weight matrix cho tất cả các từ tương tự như trong FNNLM. Mô hình CBOW sử dụng các đại diện phân phối liên tục của ngữ cảnh.

	Subsampling Frequent Words
Trong hầu hết các trường hợp đối phó với dữ liệu văn bản, kích thước của từ vựng có thể tăng lên một số lượng lớn những từ ngữ độc đáo và có thể gồm các kích thước khác nhau của các từ. Chọn các từ để giữ cho mục đích mô hình, tần số của từ có thể được dùng để quyết định loại bỏ từ, bằng cách kiểm tra các từ tổng thể.
Một chức năng tồn tại được sử dụng để tính toán điểm xác suất ở mức độ, có thể được sử dụng sau để đưa ra quyết định giữ hoặc loại bỏ từ vựng từ vựng. Chức năng này chiếm tần số của các từ liên quan và tỷ lệ subsampling, có thể bị chỉnh sửa:
				 
Tỷ lệ subsampling làm cho quyết định then chốt về liệu có nên giữ những từ thường hay không. Giá trị nhỏ hơn là những từ ít có khả năng được giữ để làm căn cứ gây dựng mô hình. Trong hầu hết các trường hợp, ngưỡng ưa thích được đặt lên đầu ra của chức năng tồn tại để loại bỏ các từ thường xuyên. Giá trị ưa thích là 0,001 cho tham số. Cách tiếp cận subsampling được đề cập giúp chống lại sự mất cân bằng giữa các từ hiếm và thường xuyên.
 
 Con số hiển thị biểu đồ giữa tần số của từ với điểm xác suất cuối cùng được tạo ra bởi phương pháp lấy mẫu. Không có một từ nào có thể chiếm tỷ lệ cao hơn, nên chúng ta sẽ xem xét phần biểu đồ có tỷ lệ thấp. Có ít quan sát mà chúng ta có thể tìm ra từ biểu đồ trên về phần trăm từ ngữ và mối quan hệ của chúng với số điểm được tạo ra 
	P(wi) = 1 xảy ra trong trường hợp z(wi) < = 0,0026. Nó có nghĩa là những từ với tỷ lệ phần trăm của họ thấp hơn 0,26% sẽ không được xem xét cho subsampling.
	P(wi) = 0,5 xảy ra trong trường hợp z(wi) = 0,00746. Do đó, phần trăm đòi hỏi một từ có cơ hội được giữ lại hoặc bị loại bỏ là khi nó có xắc suất 0,746%. 
	P(wi) = 0.033 xảy ra cho các trường hợp khi z(wi) =1, thậm chí dù nó bao gồm một từ duy nhất, có xác suất 96. 7% của nó được loại bỏ. 

Negative Sampling
Mẫu âm là một dạng đơn giản của the noise contrastive estimation (NCE). Nó được sử dụng như một phương án thay thế cho chức năng phân cấp.
Kích thước của weight matrix trong lớp ẩn của mô hình mạng nơron phụ thuộc vào kích thước tổng thể của từ vựng, đó là những yêu cầu cao hơn. Kết quả này là một số lượng lớn các weight parameters. Tất cả các weight parameters được cập nhật trong nhiều lần lặp đi lặp lại hàng triệu và hàng tỷ mẫu. Việc lấy mẫu âm là nguyên nhân để cập nhật weight.
Xác suất chọn mẫu “negative” phụ thuộc vào tần số của từ. Tần số cao hơn, sẽ là cơ hội cho từ “negative” được chọn. 
Các mô hình word2vec đã giúp đạt được các từ tốt hơn bằng cách sử dụng sự kết hợp của các mô hình trên một bộ sưu tập các công việc ngôn ngữ cú pháp và ngữ nghĩa. Với những tiến bộ trong các nguồn tài nguyên tính toán, các thuật toán nhanh hơn và có sẵn dữ liệu về ngôn ngữ, nó có thể tạo ra từ ngữ chất lượng cao so với các mô hình mạng thần kinh trước đó. 
